{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "978a025b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers,regularizers,metrics,optimizers\n",
    "import random\n",
    "import pandas as pd\n",
    "from scipy.linalg import sqrtm\n",
    "import pickle\n",
    "from typing import Any, Callable, Dict, List, Optional, Union\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2_as_graph\n",
    "import math\n",
    "import scipy.stats as st\n",
    "from scipy.special import comb\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "import json\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4b57936",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "config=tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
    "config.gpu_options.allow_growth=True\n",
    "sess=tf.compat.v1.Session(config=config) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e660725",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This algorithm is used to evaluate the structural redundancy of VGGNet-16\n",
    "and outputs the evaluation criteria of hidden layer redundancy as well as \n",
    "the entire redundancy evaluation criteria under each pruning parameter. \n",
    "Here, \"Lam\" refers to the pruning parameter set used in the evaluation \n",
    "algorithm, and \"repeats\" represents the number of times the pruning network \n",
    "is repeatedly fine-tuned.\"\"\"\n",
    "Lam=[1.0,0.9,0.8,0.7]\n",
    "repeats=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6846de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "y_train_onehot=tf.keras.utils.to_categorical(y_train,num_classes=10)\n",
    "y_test_onehot=tf.keras.utils.to_categorical(y_test,num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06d17561-978c-48b1-93a2-c9792dac902c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_dist_VGGNet_16.pkl', 'rb') as f:\n",
    "    [x_dist,y_dist]=pickle.load(f)\n",
    "x_dist=x_dist.numpy()\n",
    "y_dist=y_dist.numpy().reshape(len(y_dist),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5118f35-00d8-4e55-b9a1-904e819a2341",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_dist_VGGNet_16.pkl', 'rb') as f:\n",
    "    X=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23cf73a0-4e29-4850-84a6-36bc2ad0fc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_lr = 0.1\n",
    "weight_decay = 1e-4\n",
    "epochs = 200\n",
    "warmup_epochs = 5\n",
    "batch_size = 128\n",
    "image_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ad09d9e-8e3e-47cb-bb3a-d8cfd6438ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WarmUpCosine(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, base_lr, total_steps, warmup_steps, warmup_lr=0.0):\n",
    "        super().__init__()\n",
    "        self.base_lr = base_lr\n",
    "        self.total_steps = total_steps\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.warmup_lr = warmup_lr\n",
    "    def __call__(self, step):\n",
    "        if step is None:\n",
    "            step = tf.constant(0)\n",
    "        step = tf.cast(step, tf.float32)\n",
    "        warmup_steps = tf.cast(self.warmup_steps, tf.float32)\n",
    "        total_steps = tf.cast(self.total_steps, tf.float32)\n",
    "        warmup_percent_done = step / warmup_steps\n",
    "        learning_rate = tf.where(\n",
    "            step < warmup_steps,\n",
    "            self.warmup_lr + (self.base_lr - self.warmup_lr) * warmup_percent_done,\n",
    "            self.base_lr * 0.5 * (1.0 + tf.cos(math.pi * (step - warmup_steps) / (total_steps - warmup_steps)))\n",
    "        )\n",
    "        return learning_rate\n",
    "    def get_config(self):\n",
    "        return {\n",
    "            \"base_lr\": self.base_lr,\n",
    "            \"total_steps\": self.total_steps,\n",
    "            \"warmup_steps\": self.warmup_steps,\n",
    "            \"warmup_lr\": self.warmup_lr,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0caeafe-254f-40d0-b706-f5c279949c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomWeightDecaySGD(tf.keras.optimizers.SGD):\n",
    "    def __init__(self, weight_decay, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.weight_decay = weight_decay\n",
    "    def apply_gradients(self, grads_and_vars, name=None, experimental_aggregate_gradients=True):\n",
    "        super().apply_gradients(grads_and_vars, name, experimental_aggregate_gradients)\n",
    "        for grad, var in grads_and_vars:\n",
    "            if ('kernel' in var.name) and ('bn' not in var.name.lower()):\n",
    "                var.assign_sub(self.weight_decay * var)\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"weight_decay\": float(self.weight_decay),  \n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c6dd4ae-02b4-49ed-a2e0-7bdb0f123a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LastNSaver(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, n=10):\n",
    "        super().__init__()\n",
    "        self.n = n\n",
    "        self.history = deque(maxlen=n)  \n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_acc = logs.get(\"val_accuracy\")\n",
    "        if val_acc is not None:\n",
    "            weights = self.model.get_weights()\n",
    "            self.history.append((val_acc, weights))\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if not self.history:\n",
    "            return\n",
    "        best_acc, best_weights = max(self.history, key=lambda x: x[0])\n",
    "        print(f\" Using best val_acc={best_acc:.4f} from last {self.n} epochs\")\n",
    "        self.model.set_weights(best_weights)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3c228ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_VGG():\n",
    "    model = tf.keras.models.load_model('VGG16_cifar10.h5',custom_objects={\n",
    "        'CustomWeightDecaySGD': CustomWeightDecaySGD,\n",
    "        'WarmUpCosine': WarmUpCosine\n",
    "    })\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11f828df-773c-4895-a94a-0ae5d5338a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_VGG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7776e31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 64)        1728      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32, 32, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 64)        36864     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32, 32, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 16, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 128)       73728     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 16, 16, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 128)       147456    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 16, 16, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 8, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 8, 8, 256)         294912    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 8, 8, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 8, 8, 256)         589824    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 8, 8, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 8, 8, 256)         589824    \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 8, 8, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 4, 4, 512)         1179648   \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 4, 4, 512)        2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 4, 4, 512)         2359296   \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 4, 4, 512)        2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 4, 4, 512)         2359296   \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 4, 4, 512)        2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 2, 2, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 2, 2, 512)         2359296   \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 2, 2, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 2, 2, 512)         2359296   \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 2, 2, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 2, 2, 512)         2359296   \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 2, 2, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_12 (Activation)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 1, 1, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               262656    \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_13 (Activation)  (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_14 (Activation)  (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,261,898\n",
      "Trainable params: 15,251,402\n",
      "Non-trainable params: 10,496\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44e0448d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG_model(NN,input_shape=(32,32,3),num_class=10,d=512):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(layers.Conv2D(filters=NN[0], kernel_size=(3, 3), padding='same'\n",
    "                            ,input_shape=input_shape,use_bias=False))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Activation('relu'))\n",
    "    model.add(layers.Conv2D(NN[1], (3, 3),padding='same',use_bias=False))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Activation('relu'))\n",
    "    \n",
    "    #2\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Conv2D(NN[2], (3, 3), padding='same',use_bias=False))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Activation('relu'))\n",
    "    model.add(layers.Conv2D(NN[3], (3, 3), padding='same',use_bias=False))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Activation('relu'))\n",
    "    #5\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Conv2D(NN[4], (3, 3), padding='same',use_bias=False))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Activation('relu'))\n",
    "    model.add(layers.Conv2D(NN[5], (3, 3), padding='same',use_bias=False))\n",
    "    model.add(tf.keras.layers.BatchNormalization()) \n",
    "    model.add(tf.keras.layers.Activation('relu'))\n",
    "    model.add(layers.Conv2D(NN[6], (3, 3), padding='same',use_bias=False))\n",
    "    model.add(tf.keras.layers.BatchNormalization()) \n",
    "    model.add(tf.keras.layers.Activation('relu'))\n",
    "    #10\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Conv2D(NN[7], (3, 3), padding='same',use_bias=False))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Activation('relu'))\n",
    "    model.add(layers.Conv2D(NN[8], (3, 3), padding='same',use_bias=False))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Activation('relu'))\n",
    "    model.add(layers.Conv2D(NN[9], (3, 3), padding='same',use_bias=False))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Activation('relu'))\n",
    "    #15\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Conv2D(NN[10], (3, 3), padding='same',use_bias=False))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Activation('relu'))\n",
    "    model.add(layers.Conv2D(NN[11], (3, 3), padding='same',use_bias=False))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Activation('relu'))\n",
    "    model.add(layers.Conv2D(NN[12], (3, 3), padding='same',use_bias=False))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Activation('relu'))\n",
    "    #\n",
    "    #25\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(d))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Activation('relu'))\n",
    "    model.add(layers.Dense(d))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Activation('relu'))\n",
    "    model.add(layers.Dense(num_class,activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3f7bc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def JW(m, M):\n",
    "    \"\"\"\n",
    "    Compute the binary MD-LP J_w_value.\n",
    "\n",
    "    Args:\n",
    "        m: 1-D tensor of shape [d], the mean of the Minkowski difference of a \n",
    "           binary classification dataset.\n",
    "        M: 2-D tensor of shape [d, N], binary classification dataset Minkowski \n",
    "           difference set.\n",
    "           \n",
    "    Key idea:\n",
    "        - Calculate the approximate solution m_weighted for the optimal weights \n",
    "          in the MD-LP.\n",
    "        - Calculate the MD-LP based on the approximately optimal weights, and \n",
    "          perform a left truncation at 0.5. \n",
    "    Returns:\n",
    "        Binary MD-LP value.\n",
    "    \"\"\"\n",
    "    row_norm_sq = tf.reduce_sum(tf.square(M), axis=1)  \n",
    "    reciprocal_norm = tf.where(row_norm_sq != 0,\n",
    "                               tf.math.reciprocal(row_norm_sq),\n",
    "                               tf.zeros_like(row_norm_sq))  \n",
    "    m_weighted = m * reciprocal_norm  \n",
    "    m_weighted = tf.reshape(m_weighted, [1, -1])  \n",
    "    mM = tf.matmul(m_weighted, M)\n",
    "    L1 = tf.reduce_sum(mM)\n",
    "    L_1 = tf.reduce_sum(tf.abs(mM))\n",
    "    J_w_value = tf.abs(L1) / (L_1 + 1e-8)\n",
    "    J_w_value = tf.maximum(J_w_value, 0.5)\n",
    "    return J_w_value\n",
    "def W(X, Y, k, n_c=10):\n",
    "    \"\"\"\n",
    "    This function is used to calculate the top k largest binary classification \n",
    "    problems MD-LP used in the multi-classification problem calculation. Here, \n",
    "    the binary classification problems are obtained by combining each pair of \n",
    "    categories of the multi-classification problem.\n",
    "    Args:\n",
    "        X: Tensor/array of shape [b, l, w]. Channel output.\n",
    "        Y: Tensor/array of labels of shape [b]. Data labels.\n",
    "        k: Number of the largest binary MD-LP to keep.\n",
    "        n_c: Number of classes.\n",
    "    Returns:\n",
    "        JK_list: Tensor of shape [k], the top-k MD-LP.\n",
    "    \"\"\"\n",
    "    b, l, w = X.shape\n",
    "    X = tf.reshape(X, [b, l*w])   # flatten\n",
    "    J_list = []\n",
    "    for i, j in itertools.combinations(range(n_c), 2):\n",
    "        mask_1 = tf.reshape(tf.equal(Y, i), [-1])\n",
    "        mask_2 = tf.reshape(tf.equal(Y, j), [-1])\n",
    "        X1 = tf.boolean_mask(X, mask_1)\n",
    "        X2 = tf.boolean_mask(X, mask_2)\n",
    "        n1 = tf.shape(X1)[0]\n",
    "        n2 = tf.shape(X2)[0]\n",
    "        m_i = tf.reduce_sum(X1, axis=0) * tf.cast(n2, tf.float32) - tf.reduce_sum(X2, axis=0) * tf.cast(n1, tf.float32)\n",
    "        m_i = m_i / tf.linalg.norm(m_i + 1e-8)\n",
    "        M_i = tf.reshape(X1[:, None, :] - X2[None, :, :], [-1, l*w])\n",
    "        M_i = tf.transpose(M_i)\n",
    "        J = JW(m_i, M_i)\n",
    "        J_list.append(J)\n",
    "    J_list = tf.stack(J_list)\n",
    "    JK_list , JK_inde = tf.math.top_k(J_list,k)\n",
    "    return JK_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b9cb555-36ab-43c1-acc1-b9da528f8b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_channel(x_L, y, prune_rate, nnn=45, alpha=2.5, eps=1e-8):\n",
    "    \"\"\"\n",
    "    This function computes the structural redundancy evaluation criterion R_L\n",
    "    for a convolutional hidden layer and determines the set of retained channel\n",
    "    indices `channel_i_label` used by the pruning algorithm.\n",
    "    \n",
    "    Given the output of a convolutional layer, this function will execute:\n",
    "    - Treating each channel independently and computing a multi-class MD-LP \n",
    "      via function W;\n",
    "    - By applying nonlinear transformation, a TCR measure is constructed \n",
    "      to enhance the separability of MD-LP.\n",
    "    - By analyzing the propensity calculation of TCR measure, an evaluation \n",
    "      criterion for evaluating the redundancy of convolutional layers is derived.\n",
    "    - Based on the TCR measure, the pruning threshold is calculated and the \n",
    "      channels that remain after pruning are selected.\n",
    "    \n",
    "    Key Args:\n",
    "    x_L (Tensor):\n",
    "        Output of a convolutional hidden layer, with shape \n",
    "        [batch_size, height, width, channels].\n",
    "    y (Tensor):\n",
    "        Ground-truth labels corresponding to the input samples.\n",
    "    prune_rate (float):\n",
    "        Pruning parameter. Used to control the strictness of pruning.\n",
    "    alpha (float, optional):\n",
    "        LP transformation parameter. Used to enhance the separability \n",
    "        of the MD-LP close to 1.\n",
    "    \n",
    "    Returns:\n",
    "    channel_i_label (ndarray):\n",
    "        Indices of channels retained after pruning.\n",
    "    R_L (float):\n",
    "        Structural redundancy evaluation criterion of the layer,\n",
    "    \"\"\"\n",
    "    a, b, d, c = x_L.shape\n",
    "    jw = tf.zeros([c], dtype=tf.float32)\n",
    "    alpha = tf.cast(alpha, tf.float32)\n",
    "    for j in tf.range(c):\n",
    "        N_tf = W(x_L[:,:,:,j], y, nnn)\n",
    "        jw_j = tf.norm(N_tf) / tf.sqrt(float(nnn))\n",
    "        jw_j = (tf.exp(alpha * (2*jw_j-1)) - 1.0) / (tf.exp(alpha) - 1.0)\n",
    "        jw = tf.tensor_scatter_nd_update(jw, [[j]], [jw_j])\n",
    "    jw_min = tf.maximum(tf.reduce_min(jw) - eps, 0.0)\n",
    "    jw_max = tf.reduce_max(jw)\n",
    "    me = tf.sqrt(tf.reduce_mean(tf.square(jw - jw_min)))\n",
    "    jd = jw_min + prune_rate * me\n",
    "    mean = tf.maximum(tf.reduce_mean(jw) - eps, 0.0)\n",
    "    R_L = tf.reduce_mean(tf.sign(jw - mean))\n",
    "    channel_i_label = tf.where(jw >= jd)[:,0]\n",
    "    return channel_i_label.numpy(), R_L.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "accd1a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_model(model,x,y,prune_rate):\n",
    "    \"\"\"\n",
    "    Structured Channel Pruning Function Based on MD-LP (Channel-wise Pruning) \n",
    "    \n",
    "    This function performs channel pruning on the VGGNet-16:\n",
    "    - After each convolutional layer, based on the current layer's output x_L1 and the label y,\n",
    "    the retained channel index channel_new_label is generated by the functionprune_channel;\n",
    "    - Only the selected input/output channels are retained, while simultaneously pruning \n",
    "    the convolution kernels and BN parameters;\n",
    "    - The pruned features continue to be the input for the next layer, achieving layer-by-layer \n",
    "    cascaded pruning. \n",
    "    \n",
    "    Input:\n",
    "    model : Original Keras VGGNet-16\n",
    "    x : Network input samples (used for forward propagation and channel evaluation)\n",
    "    y : Sample labels (used for metric calculation in prune_channel)\n",
    "    prune_rate : Pruning parameter\n",
    "    \n",
    "    Output:\n",
    "    wb_list: List of weights for each convolutional / fully connected layer after pruning\n",
    "    bn_list: Parameters (gamma, beta, mean, var) for each BN layer after pruning\n",
    "    channel_label: Record of the number of retained channels for each convolutional layer \n",
    "    \"\"\"\n",
    "    x_L=x\n",
    "    wb_list=[]\n",
    "    bn_list=[]\n",
    "    channel_old_label=[0,1,2]\n",
    "    channel_label=[]\n",
    "    LLLL=0\n",
    "    N=len(model.layers)\n",
    "    for i in range(N):\n",
    "        layer=model.layers[i]\n",
    "        if \"conv2d\" in layer.name:\n",
    "            bn_layer=model.layers[i+1]\n",
    "            weight=layer.get_weights()\n",
    "            gamma,beta,mean,var=bn_layer.get_weights()\n",
    "            c_L=np.prod(weight[0].shape)\n",
    "            # =========================\n",
    "            # Prune the input channels of the current convolution based on the retained \n",
    "            # channels from the previous layer, and perform forward propagation to obtain \n",
    "            # the output features of the current layer, which will be used as the input \n",
    "            # of the layer pruning function prune_channel.\n",
    "            # =========================\n",
    "            weight[0]=weight[0][:,:,channel_old_label,:]\n",
    "            x_L1=tf.nn.conv2d(x_L,weight[0],strides=1,padding=\"SAME\")\n",
    "            x_L1=tf.nn.batch_normalization(x_L1,mean=mean,\n",
    "                                          variance=var,\n",
    "                                          offset=beta,\n",
    "                                          scale=gamma,variance_epsilon=1e-5)\n",
    "            x_L1=tf.nn.relu(x_L1)\n",
    "            # =========================\n",
    "            # Key Step: Channel Pruning in Convolutional Layer\n",
    "            # The function \"prune_channel\" calculates the TCR index based on the MD-LP \n",
    "            # of each channel and compares it with the hidden layer pruning threshold, \n",
    "            # thereby obtaining the channels that will be retained after pruning. \n",
    "            # =========================\n",
    "            channel_new_label,r_l=prune_channel(x_L1,y,prune_rate)\n",
    "            # =========================\n",
    "            # Based on the pruning results, adjust the output channels of the convolution \n",
    "            # kernel and the BN parameters, and then perform a forward pass again as the \n",
    "            # input for the next layer.\n",
    "            # =========================\n",
    "            weight[0]=weight[0][:,:,:,channel_new_label]\n",
    "            gamma=gamma[channel_new_label]\n",
    "            beta=beta[channel_new_label]\n",
    "            mean=mean[channel_new_label]\n",
    "            var=var[channel_new_label]\n",
    "            x_L=tf.nn.conv2d(x_L,weight[0],strides=1,padding=\"SAME\")\n",
    "            x_L=tf.nn.batch_normalization(x_L,mean=mean,\n",
    "                                          variance=var,\n",
    "                                          offset=beta,\n",
    "                                          scale=gamma,variance_epsilon=1e-5)\n",
    "            print(len(channel_new_label))\n",
    "            wb_list.append(weight)\n",
    "            bn_list.append([gamma,beta,mean,var])\n",
    "            channel_old_label=deepcopy(channel_new_label)\n",
    "            channel_label.append(len(channel_new_label))\n",
    "        if \"max_pooling2d\" in layer.name:\n",
    "            x_L=tf.nn.max_pool(x_L,ksize=[1, 2, 2, 1],strides=[1, 2, 2, 1],padding='VALID',name=\"pool\")\n",
    "        if i<(N-8) and \"activation\" in layer.name:\n",
    "            x_L=tf.nn.relu(x_L)\n",
    "        if i>(N-7) and \"batch_normalization\" in layer.name:\n",
    "            gamma,beta,mean,var=layer.get_weights()\n",
    "            bn_list.append([gamma,beta,mean,var])\n",
    "        if \"dense\" in layer.name:\n",
    "            weight,bias=layer.get_weights()\n",
    "            if LLLL==0:\n",
    "                weight=weight[channel_new_label]\n",
    "                LLLL+=1\n",
    "            wb_list.append([weight,bias])\n",
    "    return wb_list,bn_list,channel_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "545c4661-aad2-43fb-b07e-d1131d3f8b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pr(model,wb_list,bn_list,channel_label):\n",
    "    \"\"\"This function is used to construct a pruned network by using \n",
    "    the given pruned network structure and parameters.\"\"\"\n",
    "    t1=0\n",
    "    t2=0\n",
    "    model_p=VGG_model(channel_label)\n",
    "    for layer in model_p.layers:\n",
    "        if \"conv2d\" in layer.name:\n",
    "            temp=layer.get_weights()\n",
    "            temp=wb_list[t1]\n",
    "            layer.set_weights(temp)\n",
    "            t1+=1\n",
    "        if \"batch_normalization\" in layer.name:\n",
    "            temp=layer.get_weights()\n",
    "            temp[0]=bn_list[t2][0]\n",
    "            temp[1]=bn_list[t2][1]\n",
    "            temp[2]=bn_list[t2][2]\n",
    "            temp[3]=bn_list[t2][3]\n",
    "            layer.set_weights(temp)\n",
    "            t2+=1\n",
    "        if \"dense\" in layer.name:\n",
    "            temp=layer.get_weights()\n",
    "            temp[0]=wb_list[t1][0]\n",
    "            temp[1]=wb_list[t1][1]\n",
    "            layer.set_weights(temp)\n",
    "            t1+=1\n",
    "    return model_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ca2e307-9ac5-4479-a6b9-7fb607526316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrain(model,x_train,y_train,x_test,y_test):\n",
    "    \"\"\"This function is used to fine-tune the pruned network \n",
    "    using the same method as the original network training.\"\"\"\n",
    "    total_steps = epochs * (x_train.shape[0] // batch_size)\n",
    "    warmup_steps = warmup_epochs * (x_train.shape[0] // batch_size)\n",
    "    lr_schedule = WarmUpCosine(initial_lr, total_steps, warmup_steps)\n",
    "    optimizer = CustomWeightDecaySGD(weight_decay=weight_decay,learning_rate=lr_schedule,momentum=0.9,nesterov=True)\n",
    "    loss_fn=tf.keras.losses.CategoricalCrossentropy()\n",
    "    model.compile(optimizer=optimizer,loss=loss_fn,metrics=['accuracy'])\n",
    "    saver = LastNSaver(n=20)\n",
    "    model.fit(datagen.flow(x_train, y_train_onehot,batch_size=batch_size),\n",
    "                            steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                            epochs=epochs,\n",
    "                            validation_data=(x_test, y_test_onehot),verbose=2,callbacks=[saver])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2ca5b78-3168-4965-8fe1-cb25ee873918",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "            samplewise_center=False,  # set each sample mean to 0\n",
    "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "            samplewise_std_normalization=False,  # divide each input by its std\n",
    "            zca_whitening=False,  # apply ZCA whitening\n",
    "            rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "            height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "            horizontal_flip=True,  # randomly flip images\n",
    "            vertical_flip=False)  # randomly flip images\n",
    "        # (std, mean, and principal components if ZCA whitening is applied).\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7681570",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"These functions are used to calculate the FLOPs \n",
    "and the number of parameters of the network.\"\"\"\n",
    "def conv_flops_params(layer, input_shape):\n",
    "    h_in, w_in, cin = input_shape[1:]\n",
    "    h_out, w_out, cout = layer.output_shape[1:]\n",
    "    k_h, k_w = layer.kernel_size\n",
    "    flops = h_out * w_out * cin * cout * k_h * k_w\n",
    "    params = cin * cout * k_h * k_w\n",
    "    if layer.use_bias:\n",
    "        params += cout\n",
    "    return flops, params, (h_out, w_out, cout)\n",
    "def dense_flops_params(layer, input_shape):\n",
    "    cin = input_shape[-1]\n",
    "    cout = layer.units\n",
    "    flops = cin * cout\n",
    "    params = cin * cout\n",
    "    if layer.use_bias:\n",
    "        params += cout\n",
    "    return flops, params, (cout,)\n",
    "def compute_flops_params(model, input_shape=(32, 32, 3)):\n",
    "    total_flops = 0\n",
    "    total_params = 0\n",
    "    dummy_input = tf.zeros((1, *input_shape))\n",
    "    _ = model(dummy_input)\n",
    "    current_shape = (1, *input_shape)\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "            flops, params, out_shape = conv_flops_params(layer, current_shape)\n",
    "            total_flops += flops\n",
    "            total_params += params\n",
    "            current_shape = (1, *out_shape)\n",
    "        elif isinstance(layer, tf.keras.layers.Dense):\n",
    "            flops, params, out_shape = dense_flops_params(layer, current_shape)\n",
    "            total_flops += flops\n",
    "            total_params += params\n",
    "            current_shape = (1, *out_shape)\n",
    "    return total_flops, total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d21e086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_C(model):\n",
    "    \"\"\"This function is used to obtain the number of channels of the network.\"\"\"\n",
    "    C_L=[]\n",
    "    for i in range(len(model.variables)):\n",
    "        tensor=model.variables[i].numpy()\n",
    "        if (\"conv2d\" in model.variables[i].name) and (\"kernel\" in model.variables[i].name):\n",
    "            a,b,d,c=tensor.shape\n",
    "            C_L.append(c)\n",
    "    return C_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eaa8f576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def R_layers(model,x,y):\n",
    "    \"\"\"This function is used to obtain the structural redundancy \n",
    "    criterion of each convolutional layer in the VGGNet-16 network.\"\"\"\n",
    "    layer_outputs =[layer.output for layer in model.layers] \n",
    "    activation_model = tf.keras.models.Model(inputs=model.input,outputs=layer_outputs)\n",
    "    layer_x=activation_model.predict(x)\n",
    "    R_L=[]\n",
    "    RR_L=[]\n",
    "    C_L=[]\n",
    "    channel_label=[]\n",
    "    for i in range(len(model.layers)):\n",
    "        if \"conv2d\" in model.layers[i].name:\n",
    "            print('start')\n",
    "            weight=model.layers[i].get_weights()[0]\n",
    "            c_L=np.prod(weight.shape)\n",
    "            x_L=layer_x[i+2]\n",
    "            channel_new_label,r_L=prune_channel(x_L,y,0,nnn=15)\n",
    "            print('finish')\n",
    "            r_L=float(r_L)\n",
    "            R_L.append(r_L)\n",
    "            print(r_L)\n",
    "            C_L.append(c_L)\n",
    "            RR_L.append(r_L)\n",
    "    R_L=np.array(R_L)\n",
    "    R=np.mean(R_L)\n",
    "    return R,RR_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67858e76-d75c-42d5-8732-7d86d90b2ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2649 - accuracy: 0.9317\n",
      "313725952\n"
     ]
    }
   ],
   "source": [
    "P_list=[]\n",
    "E_list=[]\n",
    "F_list=[]\n",
    "#RP_list=[]\n",
    "#RRP_list=[]\n",
    "C_list=[]\n",
    "flops,par=compute_flops_params(model)\n",
    "loss, acc = model.evaluate(x_test, y_test_onehot)\n",
    "C_0=model_C(model)\n",
    "print(flops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6af47f31-dee1-421a-9c35-e8936ee91b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_FILE = \"training_VGGNet16_log.json\"\n",
    "def load_progress():\n",
    "    if os.path.exists(SAVE_FILE):\n",
    "        with open(SAVE_FILE, \"r\") as f:\n",
    "            return json.load(f)\n",
    "    return {\"results\": [], \n",
    "            \"RR_L\": [],\n",
    "            \"P_list\": [],\n",
    "            \"E_list\": [],\n",
    "            \"F_list\": [],\n",
    "            \"C_list\": [],\n",
    "            \"last_lam_idx\": 0,\n",
    "            \"last_repeat\": 0,\n",
    "            \"RL_exist\": 0,\n",
    "            \"Cri_exist\": 0}\n",
    "def save_progress(progress):\n",
    "    with open(SAVE_FILE, \"w\") as f:\n",
    "        json.dump(progress, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40359af5-0d54-4313-ba3d-6963059dadcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "progress = load_progress()\n",
    "start_lr_idx = progress[\"last_lam_idx\"]\n",
    "start_repeat = progress[\"last_repeat\"]\n",
    "If_RL = progress[\"RL_exist\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c37c09db-8e01-4b97-808e-23c14cacb08d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "finish\n",
      "0.125\n",
      "start\n",
      "finish\n",
      "0.1875\n",
      "start\n",
      "finish\n",
      "0.265625\n",
      "start\n",
      "finish\n",
      "0.265625\n",
      "start\n",
      "finish\n",
      "0.125\n",
      "start\n",
      "finish\n",
      "0.125\n",
      "start\n",
      "finish\n",
      "0.1484375\n",
      "start\n",
      "finish\n",
      "0.14453125\n",
      "start\n",
      "finish\n",
      "0.2734375\n",
      "start\n",
      "finish\n",
      "0.44921875\n",
      "start\n",
      "finish\n",
      "0.9609375\n",
      "start\n",
      "finish\n",
      "0.6171875\n",
      "start\n",
      "finish\n",
      "0.90625\n"
     ]
    }
   ],
   "source": [
    "if If_RL == 0:\n",
    "    model=load_VGG()\n",
    "    R_L,RR_L=R_layers(model,x_dist,y_dist)\n",
    "    progress[\"RR_L\"].append(RR_L)\n",
    "    progress[\"RL_exist\"] = 1\n",
    "    save_progress(progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d37dbc44-a9ba-4750-a32b-ce75798a5ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.125, 0.1875, 0.265625, 0.265625, 0.125, 0.125, 0.1484375, 0.14453125, 0.2734375, 0.44921875, 0.9609375, 0.6171875, 0.90625]]\n"
     ]
    }
   ],
   "source": [
    "print(progress[\"RR_L\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "94c30599-c7f9-480a-a715-441494de1b14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for lam_idx in range(start_lr_idx, len(Lam)):\n",
    "    lam = Lam[lam_idx]\n",
    "    for rep in range(start_repeat, repeats):\n",
    "        print(f\"\\n lambda: Lam={lam}, Repeat={rep+1}/{repeats}\")\n",
    "        if progress[\"Cri_exist\"] == 0:\n",
    "            model=load_VGG()\n",
    "            wb_list,bn_list,channel_label=prune_model(model,x_dist,y_dist,lam)\n",
    "            model_p=model_pr(model,wb_list,bn_list,channel_label)\n",
    "            flops_p,par_p=compute_flops_params(model_p)\n",
    "            P_=par_p/par\n",
    "            F=flops_p/flops\n",
    "            C_P=model_C(model_p)\n",
    "            print(flops_p,flops)\n",
    "            progress[\"P_list\"].append(P_)\n",
    "            progress[\"F_list\"].append([flops_p,F])\n",
    "            progress[\"C_list\"].append([C_P])\n",
    "            progress[\"Cri_exist\"] = 1\n",
    "            save_progress(progress)\n",
    "            model_p.save(\"VGG_16_pruned.h5\")\n",
    "        else:\n",
    "            model_p=tf.keras.models.load_model('VGG_16_pruned.h5',custom_objects={\n",
    "                'CustomWeightDecaySGD': CustomWeightDecaySGD,\n",
    "                'WarmUpCosine': WarmUpCosine})\n",
    "            flops_p,par_p=compute_flops_params(model_p)\n",
    "            F=flops_p/flops\n",
    "            print(flops_p,flops)\n",
    "        retrain(model_p,x_train,y_train_onehot,x_test,y_test_onehot)\n",
    "        loss_p, acc_p = model_p.evaluate(x_test, y_test_onehot)\n",
    "        print(f\" Finished: Lam={lam}, Repeat={rep+1}, Acc={acc_p:.4f}\")\n",
    "        progress[\"results\"].append(acc_p)\n",
    "        progress[\"last_lam_idx\"] = lam_idx\n",
    "        progress[\"last_repeat\"] = rep+1\n",
    "        save_progress(progress)\n",
    "    progress[\"E_list\"].append(sum(progress[\"results\"])/(repeats*acc))\n",
    "    progress[\"results\"]=[]\n",
    "    progress[\"Cri_exist\"] = 0\n",
    "    progress[\"last_repeat\"] = 0\n",
    "    progress[\"last_lam_idx\"] = lam_idx + 1\n",
    "    start_repeat=0\n",
    "    save_progress(progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70a0531-a7b5-47b0-bf6f-26e0e39948d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72eb32b7-d8d1-4d37-9955-e950934031dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9223, 0.9238, 0.922]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0.9223,0.9238,0.9220]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e46ee795-2b56-41e9-891f-cb3822534039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9283, 0.9303, 0.9247]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0.9283,0.9303,0.9247]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b1ce9a91-30c1-492e-b328-984a0baf140d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9304, 0.9307, 0.929]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0.9304,0.9307,0.9290]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "81ac2d53-ac18-48af-a939-f3e4e6c07932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9322, 0.9313, 0.9321]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0.9322,0.9313,0.9321]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8b38b3-064c-4b0d-b8f5-16156e39a704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2409614b-cfcd-4e79-8a31-865ae53ff73f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d94ca34-f160-46fa-a7c4-b2377423e5dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f743e943-0fb2-48e5-a154-fc5b4123b925",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3425f804-e737-4300-88d9-168a3168b85b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.22846725778638094,\n",
       " 0.3692149928619729,\n",
       " 0.5341196251718894,\n",
       " 0.667757546697027]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "progress[\"P_list\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1f726166-63b6-48f0-9140-cf52fc8773fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[73560432, 0.23447353185496111],\n",
       " [115660020, 0.36866577107398496],\n",
       " [164275816, 0.523628392719006],\n",
       " [188973436, 0.6023519405879435]]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "progress[\"F_list\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "94e8423e-75fd-4b2b-bd0a-c9ec8efc0c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9903402346006086, 0.995778350814889, 0.99821117824977, 1.0001788928373687]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "progress[\"E_list\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c7a56432-fea3-452b-9ae8-a19f188e7db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[27, 33, 78, 62, 135, 123, 120, 207, 225, 242, 254, 229, 222]],\n",
       " [[31, 38, 98, 84, 147, 159, 160, 273, 266, 347, 341, 305, 249]],\n",
       " [[34, 42, 115, 97, 178, 188, 201, 338, 341, 410, 419, 356, 302]],\n",
       " [[36, 50, 115, 95, 184, 201, 204, 338, 402, 475, 486, 399, 365]]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "progress[\"C_list\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6e9e04-13f0-431f-9589-d88923d5ff2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252da9eb-f2e2-4a08-8919-35db365f41b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
