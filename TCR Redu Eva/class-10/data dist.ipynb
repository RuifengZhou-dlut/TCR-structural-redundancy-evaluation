{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8396b00-4af5-4d54-ba21-6bceff0e176b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers,regularizers,metrics,optimizers\n",
    "import random\n",
    "import pandas as pd\n",
    "from scipy.linalg import sqrtm\n",
    "import pickle\n",
    "from typing import Any, Callable, Dict, List, Optional, Union\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2_as_graph\n",
    "import math\n",
    "import scipy.stats as st\n",
    "from scipy.special import comb\n",
    "from collections import defaultdict\n",
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa1c5746-1758-4d78-aa81-3b8f936c4d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "import os\n",
    "config=tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
    "config.gpu_options.allow_growth=True\n",
    "sess=tf.compat.v1.Session(config=config) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03cef2e7-5a52-4d00-903a-450b55617c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "y_train_onehot=tf.keras.utils.to_categorical(y_train,num_classes=10)\n",
    "y_test_onehot=tf.keras.utils.to_categorical(y_test,num_classes=10)\n",
    "y_train=y_train.reshape(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc099499",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code is the first part of the code used to generate the redundancy evaluation algorithm's distillation data. \n",
    "This part of the code mainly learns the key features in the original data by directly studying the \n",
    "similarities in the means and variances of the distillation data and the original data (or the \n",
    "features extracted by the feature extractor), thereby obtaining distillation data that is similar to \n",
    "the original data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "028ed089-b905-4699-af95-8fe343edb161",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_lr = 1e-2\n",
    "epochs = 400\n",
    "warmup_epochs = 10\n",
    "batch = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8956dbd2-bfe2-4461-8de3-a62640197542",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WarmUpCosine(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, base_lr, total_steps, warmup_steps, warmup_lr=0.0):\n",
    "        super().__init__()\n",
    "        self.base_lr = base_lr\n",
    "        self.total_steps = total_steps\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.warmup_lr = warmup_lr\n",
    "    def __call__(self, step):\n",
    "        if step is None:\n",
    "            step = tf.constant(0)\n",
    "        step = tf.cast(step, tf.float32)\n",
    "        warmup_steps = tf.cast(self.warmup_steps, tf.float32)\n",
    "        total_steps = tf.cast(self.total_steps, tf.float32)\n",
    "        warmup_percent_done = step / warmup_steps\n",
    "        learning_rate = tf.where(\n",
    "            step < warmup_steps,\n",
    "            self.warmup_lr + (self.base_lr - self.warmup_lr) * warmup_percent_done,\n",
    "            self.base_lr * 0.5 * (1.0 + tf.cos(math.pi * (step - warmup_steps) / (total_steps - warmup_steps)))\n",
    "        )\n",
    "        return learning_rate\n",
    "    def get_config(self):\n",
    "        return {\n",
    "            \"base_lr\": self.base_lr,\n",
    "            \"total_steps\": self.total_steps,\n",
    "            \"warmup_steps\": self.warmup_steps,\n",
    "            \"warmup_lr\": self.warmup_lr,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fa7809c-111c-4618-814c-9ca935141b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomWeightDecaySGD(tf.keras.optimizers.SGD):\n",
    "    def __init__(self, weight_decay, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.weight_decay = weight_decay\n",
    "\n",
    "    def apply_gradients(self, grads_and_vars, name=None, experimental_aggregate_gradients=True):\n",
    "        new_grads_and_vars = []\n",
    "        for (grad, var) in grads_and_vars:\n",
    "            if ('kernel' in var.name) and ('bn' not in var.name.lower()):\n",
    "                grad += self.weight_decay * var\n",
    "            new_grads_and_vars.append((grad, var))\n",
    "        return super().apply_gradients(new_grads_and_vars, name, experimental_aggregate_gradients)\n",
    "    def get_config(self):\n",
    "        return {\n",
    "            \"weight_decay\": self.weight_decay,\n",
    "            **super().get_config(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46f5d6f1-16ee-45cc-9a23-bfef175fe1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_R_1=keras.models.load_model(\"Res18_cifar10.h5\",custom_objects={\n",
    "        'CustomWeightDecaySGD': CustomWeightDecaySGD,\n",
    "        'WarmUpCosine': WarmUpCosine\n",
    "    })\n",
    "model_R_2=keras.models.load_model(\"Res32_cifar10.h5\",custom_objects={\n",
    "        'CustomWeightDecaySGD': CustomWeightDecaySGD,\n",
    "        'WarmUpCosine': WarmUpCosine\n",
    "    })\n",
    "model_V=keras.models.load_model(\"VGG16_cifar10.h5\",custom_objects={\n",
    "        'CustomWeightDecaySGD': CustomWeightDecaySGD,\n",
    "        'WarmUpCosine': WarmUpCosine\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11e41850-64ab-40f2-915c-05b74299eb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_CNN(input_shape=(32,32,3),):\n",
    "    \"\"\"\n",
    "    This function builds a CNN extractor for extracting image features. \n",
    "    It consists of three convolutional layers - batch normalization layers \n",
    "    - ReLU layers - max pooling layers - and is used to extract feature \n",
    "    information from the data after initialization.\n",
    "    \"\"\"\n",
    "    model_CNN=model = keras.models.Sequential()\n",
    "    model_CNN.add(layers.Conv2D(filters=8, kernel_size=(3, 3), padding='same',\n",
    "                 input_shape=input_shape))\n",
    "    \n",
    "    model_CNN.add(layers.BatchNormalization())\n",
    "    model_CNN.add(layers.Activation('relu'))\n",
    "    model_CNN.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model_CNN.add(layers.Conv2D(8, (3, 3), padding='same'))\n",
    "    model_CNN.add(layers.BatchNormalization())\n",
    "    model_CNN.add(layers.Activation('relu'))\n",
    "    model_CNN.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model_CNN.add(layers.Conv2D(8, (3, 3), padding='same'))\n",
    "    model_CNN.add(layers.BatchNormalization())\n",
    "    model_CNN.add(layers.Activation('relu'))\n",
    "    model_CNN.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model_CNN.add(layers.Flatten())\n",
    "    model_CNN.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate = 1e-3), metrics=['accuracy']) \n",
    "    return model_CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec7b8b27-d70d-4c14-9199-3adacaba0759",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(i):\n",
    "    return create_model_CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b82a20ba-f381-46fc-a96b-59bb3d3374e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "s=200\n",
    "K=10\n",
    "N=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb7e5d4-7cff-40fd-ba76-27dcd497b192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4850fbea-b1e6-4e88-a99a-10f2a9a1cf82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305fbcdc-88fc-48ab-907f-d99e9b567d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505f93cc-df9c-4405-b2fe-d713e2f7c959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93d90210-7061-4ded-8d48-f2a312a13c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dist=tf.random.normal((s*K,32,32,3),0.5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fba044fa-3a0b-487a-aaeb-54b0dbb51eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dist=tf.clip_by_value(x_dist, 0.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4342dbc8-5b26-4f09-a410-7d31568c776b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dist=np.zeros(s*K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4f1f943-8b4c-4feb-9755-0b4c6ff7e365",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(K):\n",
    "    y_dist[i*s:(i+i)*s]=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0baed0a7-b772-48ea-8c29-c13e1ecfa8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices=np.arange(s*K)\n",
    "np.random.shuffle(indices)\n",
    "x_dist=tf.gather(x_dist,indices)\n",
    "y_dist=tf.gather(y_dist,indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b05922f4-cdd5-4bd6-9af1-4d894e6ed2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_dist_10.pkl', 'wb') as f:\n",
    "    pickle.dump([0,x_train,y_train,x_dist,y_dist],f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbee5dc-5f4c-42f6-8a6d-0a38302f9e12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385b0c54-5d0e-459b-a31d-552f0448e799",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c551d30-be7c-4a6e-9b2e-db133b4b1a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aced225-b502-40b0-8f3a-7bd431da7c7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59c51b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80ad5b77-89bc-4d78-830f-f22bc0440166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_train(x,models,L,N=N,b=128):\n",
    "    f=np.zeros((N,batch,b))\n",
    "    for i in range(10):\n",
    "        model=models[i]\n",
    "        layer_outputs =[layer.output for layer in model.layers] \n",
    "        activation_model = tf.keras.models.Model(inputs=model.input, outputs=layer_outputs)\n",
    "        layer=activation_model.predict(x)\n",
    "        f[i]=layer[-1]\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e66bc73-b232-42ec-a2d3-b009c105126c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_dist(x,models,N=N,b=128):\n",
    "    x=tf.reshape(x,[s*K,32,32,3])\n",
    "    for i in range(N):\n",
    "        model=models[i]\n",
    "        if i==0:\n",
    "            f=model(x)\n",
    "            f=tf.reshape(f,[1,s*K,b])\n",
    "        else:\n",
    "            f_i=tf.reshape(model(x),[1,s*K,b])\n",
    "            f=tf.concat([f,f_i], axis=0)\n",
    "    return tf.cast(f,dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72018418-1ff8-46f6-838b-2a6fc4e5b0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_conv(x):\n",
    "    cov_xx = tfp.stats.covariance(x)\n",
    "    return cov_xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d6237d7-31e3-4061-926b-8808e0bfda31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_mean(x):\n",
    "    return tf.reduce_mean(x, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e06e661-b4d8-4b7f-a8cc-75f636c06e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_dm(x_t,x_s):\n",
    "    dm_l=tf.reduce_mean(x_t, axis=0)-tf.reduce_mean(x_s, axis=0)\n",
    "    return tf.norm(dm_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a7445dc-4dda-4d6f-a1f5-93683b97a183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_DM(x_t,x_s,y_t,y_s,K=K):\n",
    "    DM_l=tf.TensorArray(dtype=tf.float32, size=K)\n",
    "    for i in range(K):\n",
    "        x_ti=tf.boolean_mask(x_t,tf.equal(y_t,i))\n",
    "        x_si=tf.boolean_mask(x_s,tf.equal(y_s,i))\n",
    "        DDD=tf_mean(x_ti)-tf_mean(x_si)\n",
    "        DM_l=DM_l.write(i, tf.norm(DDD))\n",
    "        del x_ti,x_si\n",
    "    return tf.reduce_mean(DM_l.stack())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3c3e7c8-784d-4e42-ade4-d44ad15681d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_cov(x_t,x_s,y_t,y_s,K=K):\n",
    "    cov_l=tf.TensorArray(dtype=tf.float32, size=K)\n",
    "    for i in range(K):\n",
    "        x_ti=tf.boolean_mask(x_t,tf.equal(y_t,i))\n",
    "        x_si=tf.boolean_mask(x_s,tf.equal(y_s,i))\n",
    "        CCC=tf.norm(tf_conv(x_ti)-tf_conv(x_si))\n",
    "        cov_l=cov_l.write(i, tf.norm(CCC))\n",
    "        del x_ti,x_si\n",
    "    return tf.reduce_mean(cov_l.stack())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5f9ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"The 'loss' function calculates the difference in mean and variance \n",
    "between the original data and the distillation data. While the 'loss_lam' \n",
    "function calculates the difference in mean and variance between the \n",
    "original data and the distillation data, which are extracted features \n",
    "by multiple CNN feature extractors.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "500a5063-8f70-45af-bb8a-a308c9d89f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(x_t,x_s,y_t,y_s,lam_1):\n",
    "    dm_l=loss_DM(x_t,x_s,y_t,y_s)\n",
    "    cov_l=loss_cov(x_t,x_s,y_t,y_s)\n",
    "    return dm_l+lam_1*cov_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da8635c3-e631-4518-849d-d2da9d87357a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_lam(x_t,x_s,y_t,y_s,lam_1):\n",
    "    dm_l=np.zeros(N)\n",
    "    cov_l=np.zeros(N)\n",
    "    class_l=np.zeros(N)\n",
    "    for i in range(N):\n",
    "        dm_l[i]=loss_DM(x_t[i],x_s[i],y_t,y_s)\n",
    "        cov_l[i]=loss_cov(x_t[i],x_s[i],y_t,y_s)\n",
    "    dm_l=np.sum(dm_l)\n",
    "    cov_l=np.sum(cov_l)\n",
    "    return dm_l+lam_1*cov_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "686dce68-2e74-4f11-97ed-a6b13cd861cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_balanced_batches(data, labels, num_classes=10, samples_per_class_per_batch=200):\n",
    "    \"\"\"This function is used for stratified sampling, \n",
    "    extracting the original samples into batches of \n",
    "    the same size as the distillation dataset.\"\"\"\n",
    "    class_to_indices = defaultdict(list)\n",
    "    for idx, label in enumerate(labels):\n",
    "        class_to_indices[label].append(idx)\n",
    "    for cls in range(num_classes):\n",
    "        np.random.shuffle(class_to_indices[cls])\n",
    "    total_per_class = len(class_to_indices[0])\n",
    "    num_batches = total_per_class // samples_per_class_per_batch\n",
    "    batches = []\n",
    "    for batch_idx in range(num_batches):\n",
    "        batch_indices = []\n",
    "        for cls in range(num_classes):\n",
    "            start = batch_idx * samples_per_class_per_batch\n",
    "            end = start + samples_per_class_per_batch\n",
    "            batch_indices.extend(class_to_indices[cls][start:end])\n",
    "        np.random.shuffle(batch_indices)\n",
    "        batch_data = data[batch_indices]\n",
    "        batch_labels = labels[batch_indices]\n",
    "        batches.append((batch_data, batch_labels))\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24da5d03-2ab8-40f8-a0aa-7a37092c7299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4bb7ef-144b-42d0-911f-207e50e3df86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b89e4e-6bb4-4f6b-8c63-6c1cb13b6a6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3603937e-6c44-4497-a73f-cef22f26410f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06d566c4-c7d1-4ebd-9cbd-0d871e539f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_1(I,x_s):\n",
    "    \"\"\"\n",
    "    Data Distillation Function (Data Distillation via Feature & Statistics Matching) \n",
    "    This function directly optimizes the distilled data x_s to approximate the real \n",
    "    training data on the following two levels:\n",
    "    1) Input space statistical consistency (loss):\n",
    "    By constraining the statistics (such as mean and variance) of the real data and \n",
    "    the distillation data in the pixel space to be consistent,it ensures that the \n",
    "    distillation data approximates the original data at the overall distribution level.\n",
    "    2) Feature space consistency (loss_lam):\n",
    "    Using multiple CNN models to extract the intermediate features of the real data \n",
    "    and the distillation data, constraining the differences between the two in the \n",
    "    feature space. \n",
    "    The distillation data x_s is regarded as a trainable variable \n",
    "    and is directly updated through gradient descent, ultimately resulting in a smaller \n",
    "    but representative set of distillation samples. \n",
    "    \"\"\"\n",
    "    lr_schedule = WarmUpCosine(0.01*(10-I), 500*(10-I), 0)\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=initial_lr)\n",
    "    # =========================\n",
    "    # Outer loop: Distillation cycle\n",
    "    # Controls the total number of rounds/stages in the distillation process\n",
    "    # =========================\n",
    "    for i in range((10-I)):\n",
    "        NNN=len(y_train)//batch\n",
    "        t_batch=create_balanced_batches(x_train,y_train)\n",
    "        for j in range(NNN):\n",
    "            loss_1=0\n",
    "            loss_2=0\n",
    "            x_batch,y_batch=t_batch[j]\n",
    "            x_batch=tf.cast(x_batch,dtype=tf.float32)\n",
    "            models=[create_model(i) for i in range(10)]\n",
    "            x_t=tf.reshape(x_batch,[batch,32*32*3])\n",
    "            f_t=tf.convert_to_tensor(feature_train(x_batch,models,batch))\n",
    "            f_t=tf.cast(f_t,dtype=tf.float32)\n",
    "            # =========================\n",
    "            # Inner loop: Data distillation optimization\n",
    "            # Update x_s multiple times to match the statistics and features of the current batch\n",
    "            # =========================\n",
    "            for k in range(20):\n",
    "                with tf.GradientTape() as tape:\n",
    "                    tape.watch(x_s)\n",
    "                    x_dist=tf.reshape(x_s,[s*K,32,32,3])\n",
    "                    f_s=feature_dist(x_s,models)\n",
    "                    loss_f=loss_lam(f_t,f_s,y_batch,y_dist,lam_1)\n",
    "                    loss_x=loss(x_t,x_s,y_batch,y_dist,lam_1)\n",
    "                    loss_=loss_f+loss_x\n",
    "                grad = tape.gradient(loss_, x_s)\n",
    "                optimizer.apply_gradients(zip([grad], [x_s]))\n",
    "                x_s.assign(tf.clip_by_value(x_s, 0.0, 1.0))\n",
    "                loss_1+=loss_x\n",
    "                loss_2+=loss_f\n",
    "            if (j+1)%5==0:\n",
    "                print(loss_1,loss_2)\n",
    "                x_dist=tf.reshape(x_s,[s*K,32,32,3])\n",
    "                a1=model_R_1.evaluate(x_dist,y_dist_onehot)\n",
    "                a2=model_R_2.evaluate(x_dist,y_dist_onehot)\n",
    "                a3=model_V.evaluate(x_dist,y_dist_onehot)\n",
    "                print(i,j)\n",
    "        with open('data_dist_10.pkl', 'wb') as f:\n",
    "            pickle.dump([int(i+1),x_train,y_train,x_dist,y_dist],f)\n",
    "    return tf.reshape(x_s,[s*K,32,32,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35802345-326d-4de4-b8b0-b18e901d3b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_dist_10.pkl', 'rb') as f:\n",
    "    [I,x_train,y_train,x_dist,y_dist]=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c43ec9bc-7a81-4803-9b51-c8198c2b32e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lam_1=0.1\n",
    "y_dist_onehot=tf.keras.utils.to_categorical(y_dist,num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9444cb7b-e293-4831-83dd-b8cb7926ca73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_t=tf.reshape(x_train,[50000,32*32*3])\n",
    "x_s=tf.reshape(x_dist,[s*K,32*32*3])\n",
    "x_s=tf.Variable(x_s)\n",
    "lam_1=0.1\n",
    "y_dist_onehot=tf.keras.utils.to_categorical(y_dist,num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "998d8e43-2285-479b-84e2-eb94d882755c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce2fd800-012a-40ea-94d2-bff8409581fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(37.074142, shape=(), dtype=float32) 18.21462980397046\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 2.7485 - accuracy: 0.3455\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 3.9056 - accuracy: 0.1400\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 3.6980 - accuracy: 0.1405\n",
      "0 4\n",
      "tf.Tensor(36.39868, shape=(), dtype=float32) 18.866321595665074\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 2.6022 - accuracy: 0.3760\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 3.8463 - accuracy: 0.1470\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 3.6474 - accuracy: 0.1430\n",
      "0 9\n",
      "tf.Tensor(37.002785, shape=(), dtype=float32) 18.958274888293822\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 2.4720 - accuracy: 0.4035\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 3.7887 - accuracy: 0.1490\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 3.5814 - accuracy: 0.1580\n",
      "0 14\n",
      "tf.Tensor(35.484493, shape=(), dtype=float32) 22.888142175413662\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 2.3856 - accuracy: 0.4250\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 3.7354 - accuracy: 0.1535\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 3.5032 - accuracy: 0.1770\n",
      "0 19\n",
      "tf.Tensor(35.66543, shape=(), dtype=float32) 18.034751021768894\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 2.3267 - accuracy: 0.4375\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 3.6351 - accuracy: 0.1730\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 3.4607 - accuracy: 0.1785\n",
      "0 24\n",
      "tf.Tensor(34.09624, shape=(), dtype=float32) 19.165983937773852\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 2.1745 - accuracy: 0.4725\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 3.5850 - accuracy: 0.1775\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 3.3508 - accuracy: 0.2050\n",
      "1 4\n",
      "tf.Tensor(39.282387, shape=(), dtype=float32) 18.019937486108393\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 2.1116 - accuracy: 0.4925\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 3.5003 - accuracy: 0.1845\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 3.3081 - accuracy: 0.2175\n",
      "1 9\n",
      "tf.Tensor(35.916916, shape=(), dtype=float32) 18.824978316854686\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 2.0912 - accuracy: 0.5005\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 3.4270 - accuracy: 0.1920\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 3.2136 - accuracy: 0.2330\n",
      "1 14\n",
      "tf.Tensor(38.04923, shape=(), dtype=float32) 18.955361437215466\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 2.1042 - accuracy: 0.4955\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 3.3916 - accuracy: 0.1945\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 3.1883 - accuracy: 0.2360\n",
      "1 19\n",
      "tf.Tensor(36.87225, shape=(), dtype=float32) 20.521015103161336\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 2.0235 - accuracy: 0.5160\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 3.2915 - accuracy: 0.2160\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 3.0669 - accuracy: 0.2670\n",
      "1 24\n",
      "tf.Tensor(36.440315, shape=(), dtype=float32) 17.60856421634089\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 2.0296 - accuracy: 0.5220\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 3.2464 - accuracy: 0.2265\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 3.0077 - accuracy: 0.2795\n",
      "2 4\n",
      "tf.Tensor(37.137886, shape=(), dtype=float32) 22.58209735136479\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 1.9765 - accuracy: 0.5330\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 3.1411 - accuracy: 0.2375\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 2.9172 - accuracy: 0.2945\n",
      "2 9\n",
      "tf.Tensor(34.943275, shape=(), dtype=float32) 18.474760169908404\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.9085 - accuracy: 0.5415\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 3.0468 - accuracy: 0.2565\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 2.8177 - accuracy: 0.3230\n",
      "2 14\n",
      "tf.Tensor(36.451576, shape=(), dtype=float32) 20.192620974406598\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.9492 - accuracy: 0.5360\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 3.0175 - accuracy: 0.2645\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 2.8059 - accuracy: 0.3245\n",
      "2 19\n",
      "tf.Tensor(37.756893, shape=(), dtype=float32) 18.269497913774103\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 1.9426 - accuracy: 0.5405\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 2.8948 - accuracy: 0.2840\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 2.6737 - accuracy: 0.3545\n",
      "2 24\n",
      "tf.Tensor(37.60721, shape=(), dtype=float32) 19.936182621493934\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 1.9346 - accuracy: 0.5420\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 2.8639 - accuracy: 0.2855\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 2.6967 - accuracy: 0.3495\n",
      "3 4\n",
      "tf.Tensor(37.93902, shape=(), dtype=float32) 22.40256083421409\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 1.9145 - accuracy: 0.5625\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 2.7611 - accuracy: 0.3185\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 2.6018 - accuracy: 0.3780\n",
      "3 9\n",
      "tf.Tensor(37.974907, shape=(), dtype=float32) 22.75235091745853\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 1.8559 - accuracy: 0.5620\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 2.6926 - accuracy: 0.3250\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 2.5327 - accuracy: 0.3900\n",
      "3 14\n",
      "tf.Tensor(37.464127, shape=(), dtype=float32) 21.90271374126896\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 1.9105 - accuracy: 0.5440\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 2.6456 - accuracy: 0.3520\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 2.5288 - accuracy: 0.3945\n",
      "3 19\n",
      "tf.Tensor(35.73513, shape=(), dtype=float32) 21.28198849447072\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 1.8526 - accuracy: 0.5645\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 2.6043 - accuracy: 0.3535\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 2.4614 - accuracy: 0.4120\n",
      "3 24\n",
      "tf.Tensor(35.72076, shape=(), dtype=float32) 22.07633397271857\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 1.8393 - accuracy: 0.5630\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 2.5367 - accuracy: 0.3630\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 2.4262 - accuracy: 0.4170\n",
      "4 4\n",
      "tf.Tensor(36.423973, shape=(), dtype=float32) 17.92892493512481\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.8447 - accuracy: 0.5780\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 2.5072 - accuracy: 0.3680\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 2.4039 - accuracy: 0.4290\n",
      "4 9\n",
      "tf.Tensor(36.596874, shape=(), dtype=float32) 17.797131284326312\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 1.8227 - accuracy: 0.5735\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 2.4474 - accuracy: 0.3900\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 2.3409 - accuracy: 0.4380\n",
      "4 14\n",
      "tf.Tensor(37.06163, shape=(), dtype=float32) 18.940584540739657\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 1.8500 - accuracy: 0.5625\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 2.4051 - accuracy: 0.3980\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 2.3056 - accuracy: 0.4515\n",
      "4 19\n",
      "tf.Tensor(36.59443, shape=(), dtype=float32) 27.002053217776115\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.7911 - accuracy: 0.5810\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 2.3772 - accuracy: 0.3950\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 2.2468 - accuracy: 0.4695\n",
      "4 24\n",
      "tf.Tensor(40.228245, shape=(), dtype=float32) 18.783912373753264\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.8419 - accuracy: 0.5650\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 2.3281 - accuracy: 0.4110\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 2.2578 - accuracy: 0.4595\n",
      "5 4\n",
      "tf.Tensor(35.053444, shape=(), dtype=float32) 19.728771307971325\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.7888 - accuracy: 0.5795\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 2.2676 - accuracy: 0.4320\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 2.2268 - accuracy: 0.4720\n",
      "5 9\n",
      "tf.Tensor(38.080467, shape=(), dtype=float32) 16.228071757405996\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 1.8212 - accuracy: 0.5730\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 2.2595 - accuracy: 0.4280\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 2.2255 - accuracy: 0.4690\n",
      "5 14\n",
      "tf.Tensor(36.47826, shape=(), dtype=float32) 19.463154808897528\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.8150 - accuracy: 0.5710\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 2.2065 - accuracy: 0.4500\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 2.1850 - accuracy: 0.4860\n",
      "5 19\n",
      "tf.Tensor(36.39882, shape=(), dtype=float32) 28.739369407575573\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 1.8166 - accuracy: 0.5790\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 2.2327 - accuracy: 0.4300\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 2.2014 - accuracy: 0.4815\n",
      "5 24\n",
      "tf.Tensor(35.401752, shape=(), dtype=float32) 17.077584135369396\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 1.7849 - accuracy: 0.5850\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 2.1549 - accuracy: 0.4585\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 2.1795 - accuracy: 0.4825\n",
      "6 4\n",
      "tf.Tensor(37.252193, shape=(), dtype=float32) 17.212311610672618\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 1.7412 - accuracy: 0.6025\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 2.1337 - accuracy: 0.4680\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 2.1259 - accuracy: 0.4970\n",
      "6 9\n",
      "tf.Tensor(37.25327, shape=(), dtype=float32) 15.695139663619921\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 1.8232 - accuracy: 0.5735\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 2.1293 - accuracy: 0.4665\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 2.1619 - accuracy: 0.4900\n",
      "6 14\n",
      "tf.Tensor(37.160522, shape=(), dtype=float32) 19.677064258418973\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 1.7933 - accuracy: 0.5805\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 2.1459 - accuracy: 0.4635\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 2.2215 - accuracy: 0.4820\n",
      "6 19\n",
      "tf.Tensor(36.712883, shape=(), dtype=float32) 20.800171244051306\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 1.7915 - accuracy: 0.5830\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 2.1016 - accuracy: 0.4735\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 2.1019 - accuracy: 0.4990\n",
      "6 24\n",
      "tf.Tensor(37.66541, shape=(), dtype=float32) 21.367120665870605\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 1.7551 - accuracy: 0.5940\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 2.0296 - accuracy: 0.4885\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 2.1258 - accuracy: 0.5065\n",
      "7 4\n",
      "tf.Tensor(37.56316, shape=(), dtype=float32) 20.623692390136423\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 1.7687 - accuracy: 0.5890\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 2.0797 - accuracy: 0.4745\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 2.1318 - accuracy: 0.4955\n",
      "7 9\n",
      "tf.Tensor(36.78962, shape=(), dtype=float32) 19.66099501242861\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.7599 - accuracy: 0.5995\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 2.0056 - accuracy: 0.4970\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 2.0870 - accuracy: 0.5130\n",
      "7 14\n",
      "tf.Tensor(38.584667, shape=(), dtype=float32) 20.23280701739714\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.7682 - accuracy: 0.5930\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 2.0495 - accuracy: 0.4830\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 2.1492 - accuracy: 0.4980\n",
      "7 19\n",
      "tf.Tensor(36.380936, shape=(), dtype=float32) 21.67290561683476\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 1.7682 - accuracy: 0.5905\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 2.0177 - accuracy: 0.4960\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 2.1248 - accuracy: 0.4965\n",
      "7 24\n"
     ]
    }
   ],
   "source": [
    "x_dist=dist_1(I,x_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8af900f6-2460-4c06-8c69-235fe2c242da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 7ms/step - loss: 1.7682 - accuracy: 0.5905\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 2.0177 - accuracy: 0.4960\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 2.1248 - accuracy: 0.4965\n"
     ]
    }
   ],
   "source": [
    "a1=model_R_1.evaluate(x_dist,y_dist_onehot)\n",
    "a2=model_R_2.evaluate(x_dist,y_dist_onehot)\n",
    "a3=model_V.evaluate(x_dist,y_dist_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887f5ccd-7f6b-4ef0-962e-1b1239bcbe96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dad52f3-5b7d-46bc-adb6-385f336439bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3088868-eb47-4c01-b299-628a46c9392d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a990e74-1afc-48a0-9664-9189412c6453",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b61daa69-304b-4bb7-876c-fbc8b9e7fbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_dist_10.pkl', 'wb') as f:\n",
    "    pickle.dump([0,x_train,y_train,x_dist,y_dist],f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eaa614e4-3776-4439-b3a1-fd7176d3ba4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2.0, shape=(), dtype=float64)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m=3\n",
    "plt.imshow(x_dist[m])\n",
    "print(y_dist[m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "facb0991-13e2-44de-a4ec-8682b090e4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_dist_10.pkl', 'rb') as f:\n",
    "    [I,x_train,y_train,x_dist,y_dist]=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a457b2-4e36-4a83-b08a-66df7ba9b5b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a31bb9-711c-4c4e-842a-9c7a13039732",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be2c483-0e6d-48ed-ba9c-bbb50550f247",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8650da-665a-4b09-b6a8-19a666ae461d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
