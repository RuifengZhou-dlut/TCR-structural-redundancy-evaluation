{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dea4f2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers,regularizers,metrics,optimizers\n",
    "import random\n",
    "import pandas as pd\n",
    "from scipy.linalg import sqrtm\n",
    "import pickle\n",
    "import logging\n",
    "from typing import Any, Callable, Dict, List, Optional, Union\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2_as_graph\n",
    "import math\n",
    "import scipy.stats as st\n",
    "from scipy.special import comb\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "import json\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c459c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "config=tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
    "config.gpu_options.allow_growth=True\n",
    "sess=tf.compat.v1.Session(config=config) \n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "047a8aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This algorithm is used to evaluate the structural redundancy of ResNet-56 \n",
    "and outputs the evaluation criteria of hidden layer redundancy as well as \n",
    "the entire redundancy evaluation criteria under each pruning parameter. \n",
    "Here, \"Lam\" refers to the pruning parameter set used in the evaluation \n",
    "algorithm, and \"repeats\" represents the number of times the pruning network \n",
    "is repeatedly fine-tuned.\"\"\"\n",
    "Lam=[1.0,0.95,0.9,0.85]\n",
    "repeats=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2a42158-7dad-47c9-b86b-79b6d1ec3980",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.pkl', 'rb') as f:\n",
    "    [x_train,y_train,x_test,y_test]=pickle.load(f)\n",
    "y_train_onehot=tf.keras.utils.to_categorical(y_train,num_classes=3)\n",
    "y_test_onehot=tf.keras.utils.to_categorical(y_test,num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b90de6f5-b05a-4da8-85f9-a62abf479e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_dist_ResNet_56.pkl', 'rb') as f:\n",
    "    [x_dist,y_dist]=pickle.load(f)\n",
    "x_dist=x_dist.numpy()\n",
    "y_dist=y_dist.numpy().reshape(len(y_dist),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25b29e82-1535-4890-8962-851dfbb01ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_lr = 0.1\n",
    "weight_decay = 1e-4\n",
    "epochs = 200\n",
    "warmup_epochs = 5\n",
    "batch_size = 32\n",
    "image_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d66d49e7-17f5-4ca8-af13-e7e02c3a029e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WarmUpCosine(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, base_lr, total_steps, warmup_steps, warmup_lr=0.0):\n",
    "        super().__init__()\n",
    "        self.base_lr = base_lr\n",
    "        self.total_steps = total_steps\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.warmup_lr = warmup_lr\n",
    "    def __call__(self, step):\n",
    "        if step is None:\n",
    "            step = tf.constant(0)\n",
    "        step = tf.cast(step, tf.float32)\n",
    "        warmup_steps = tf.cast(self.warmup_steps, tf.float32)\n",
    "        total_steps = tf.cast(self.total_steps, tf.float32)\n",
    "        warmup_percent_done = step / warmup_steps\n",
    "        learning_rate = tf.where(\n",
    "            step < warmup_steps,\n",
    "            self.warmup_lr + (self.base_lr - self.warmup_lr) * warmup_percent_done,\n",
    "            self.base_lr * 0.5 * (1.0 + tf.cos(math.pi * (step - warmup_steps) / (total_steps - warmup_steps)))\n",
    "        )\n",
    "        return learning_rate\n",
    "    def get_config(self):\n",
    "        return {\n",
    "            \"base_lr\": self.base_lr,\n",
    "            \"total_steps\": self.total_steps,\n",
    "            \"warmup_steps\": self.warmup_steps,\n",
    "            \"warmup_lr\": self.warmup_lr,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a00d3648-b747-4730-8a76-75ce7c9a318c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomWeightDecaySGD(tf.keras.optimizers.SGD):\n",
    "    def __init__(self, weight_decay, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.weight_decay = weight_decay\n",
    "    def apply_gradients(self, grads_and_vars, name=None, experimental_aggregate_gradients=True):\n",
    "        super().apply_gradients(grads_and_vars, name, experimental_aggregate_gradients)\n",
    "        for grad, var in grads_and_vars:\n",
    "            if ('kernel' in var.name) and ('bn' not in var.name.lower()):\n",
    "                var.assign_sub(self.weight_decay * var)\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"weight_decay\": float(self.weight_decay),  # 确保是float\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24ed25a2-cf90-4e19-9582-0c0f772e5e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LastNSaver(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, n=10):\n",
    "        super().__init__()\n",
    "        self.n = n\n",
    "        self.history = deque(maxlen=n)  # 存最近N次 (val_acc, weights)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_acc = logs.get(\"val_accuracy\")\n",
    "        if val_acc is not None:\n",
    "            # 保存 (val_acc, 当前权重)\n",
    "            weights = self.model.get_weights()\n",
    "            self.history.append((val_acc, weights))\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        # 在最后N次中选最优\n",
    "        if not self.history:\n",
    "            return\n",
    "        best_acc, best_weights = max(self.history, key=lambda x: x[0])\n",
    "        print(f\" Using best val_acc={best_acc:.4f} from last {self.n} epochs\")\n",
    "        self.model.set_weights(best_weights)  # 恢复最佳权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47d65cd3-569b-4d19-a999-d595b1b517bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_Res():\n",
    "    model = tf.keras.models.load_model('Res_56.h5',custom_objects={\n",
    "        'CustomWeightDecaySGD': CustomWeightDecaySGD,\n",
    "        'WarmUpCosine': WarmUpCosine\n",
    "    })\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e2e2c6f-0487-4831-9852-adf0323c615a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_bn_relu(x, filters, kernel_size, strides=1):\n",
    "    x = tf.keras.layers.Conv2D(filters, kernel_size, strides=strides, padding='same',use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    return tf.keras.layers.ReLU()(x)\n",
    "\n",
    "def residual_block(x, filter1, filter2, downsample=False):\n",
    "    shortcut = x\n",
    "    strides = 2 if downsample else 1\n",
    "    x = conv_bn_relu(x, filter1, 3, strides)\n",
    "    x = tf.keras.layers.Conv2D(filter2, 3, strides=1, padding='same',use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    if downsample:\n",
    "        shortcut = tf.keras.layers.Conv2D(filter2, 1, strides=strides, padding='same',use_bias=False)(shortcut)\n",
    "        shortcut = tf.keras.layers.BatchNormalization()(shortcut)\n",
    "    x = tf.keras.layers.add([x, shortcut])\n",
    "    return tf.keras.layers.ReLU()(x)\n",
    "\n",
    "def Res_model(NN,input_shape=(32,32,3), num_classes=3):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = conv_bn_relu(inputs, NN[9], 3)\n",
    "    x = residual_block(x, NN[0], NN[9])\n",
    "    x = residual_block(x, NN[1], NN[9])\n",
    "    x = residual_block(x, NN[2], NN[9])\n",
    "    x = residual_block(x, NN[3], NN[9])\n",
    "    x = residual_block(x, NN[4], NN[9])\n",
    "    x = residual_block(x, NN[5], NN[9])\n",
    "    x = residual_block(x, NN[6], NN[9])\n",
    "    x = residual_block(x, NN[7], NN[9])\n",
    "    x = residual_block(x, NN[8], NN[9])\n",
    "    x = residual_block(x, NN[10], NN[19], downsample=True)\n",
    "    x = residual_block(x, NN[11], NN[19])\n",
    "    x = residual_block(x, NN[12], NN[19])\n",
    "    x = residual_block(x, NN[13], NN[19])\n",
    "    x = residual_block(x, NN[14], NN[19])\n",
    "    x = residual_block(x, NN[15], NN[19])\n",
    "    x = residual_block(x, NN[16], NN[19])\n",
    "    x = residual_block(x, NN[17], NN[19])\n",
    "    x = residual_block(x, NN[18], NN[19])\n",
    "    x = residual_block(x, NN[20], NN[29], downsample=True)\n",
    "    x = residual_block(x, NN[21], NN[29])\n",
    "    x = residual_block(x, NN[22], NN[29])\n",
    "    x = residual_block(x, NN[23],NN[29])\n",
    "    x = residual_block(x, NN[24],NN[29])\n",
    "    x = residual_block(x, NN[25], NN[29])\n",
    "    x = residual_block(x, NN[26], NN[29])\n",
    "    x = residual_block(x, NN[27],NN[29])\n",
    "    x = residual_block(x, NN[28],NN[29])\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    outputs = tf.keras.layers.Dense(num_classes,activation='softmax')(x)\n",
    "    return tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78515397",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_Res()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c71b4f71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 32, 32, 16)   432         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 32, 32, 16)  64          ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                   (None, 32, 32, 16)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 32, 32, 16)   2304        ['re_lu[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_1 (ReLU)                 (None, 32, 32, 16)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 32, 32, 16)   2304        ['re_lu_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 32, 32, 16)   0           ['batch_normalization_2[0][0]',  \n",
      "                                                                  're_lu[0][0]']                  \n",
      "                                                                                                  \n",
      " re_lu_2 (ReLU)                 (None, 32, 32, 16)   0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 32, 32, 16)   2304        ['re_lu_2[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_3 (ReLU)                 (None, 32, 32, 16)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 32, 32, 16)   2304        ['re_lu_3[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 32, 32, 16)   0           ['batch_normalization_4[0][0]',  \n",
      "                                                                  're_lu_2[0][0]']                \n",
      "                                                                                                  \n",
      " re_lu_4 (ReLU)                 (None, 32, 32, 16)   0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 32, 32, 16)   2304        ['re_lu_4[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_5 (ReLU)                 (None, 32, 32, 16)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 32, 32, 16)   2304        ['re_lu_5[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 32, 32, 16)   0           ['batch_normalization_6[0][0]',  \n",
      "                                                                  're_lu_4[0][0]']                \n",
      "                                                                                                  \n",
      " re_lu_6 (ReLU)                 (None, 32, 32, 16)   0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 32, 32, 16)   2304        ['re_lu_6[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_7 (ReLU)                 (None, 32, 32, 16)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 32, 32, 16)   2304        ['re_lu_7[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 32, 32, 16)   0           ['batch_normalization_8[0][0]',  \n",
      "                                                                  're_lu_6[0][0]']                \n",
      "                                                                                                  \n",
      " re_lu_8 (ReLU)                 (None, 32, 32, 16)   0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 32, 32, 16)   2304        ['re_lu_8[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_9 (ReLU)                 (None, 32, 32, 16)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 32, 32, 16)   2304        ['re_lu_9[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 32, 32, 16)  64          ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 32, 32, 16)   0           ['batch_normalization_10[0][0]', \n",
      "                                                                  're_lu_8[0][0]']                \n",
      "                                                                                                  \n",
      " re_lu_10 (ReLU)                (None, 32, 32, 16)   0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 32, 32, 16)   2304        ['re_lu_10[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 32, 32, 16)  64          ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_11 (ReLU)                (None, 32, 32, 16)   0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 32, 32, 16)   2304        ['re_lu_11[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 32, 32, 16)  64          ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 32, 32, 16)   0           ['batch_normalization_12[0][0]', \n",
      "                                                                  're_lu_10[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_12 (ReLU)                (None, 32, 32, 16)   0           ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 32, 32, 16)   2304        ['re_lu_12[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 32, 32, 16)  64          ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_13 (ReLU)                (None, 32, 32, 16)   0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 32, 32, 16)   2304        ['re_lu_13[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 32, 32, 16)  64          ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 32, 32, 16)   0           ['batch_normalization_14[0][0]', \n",
      "                                                                  're_lu_12[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_14 (ReLU)                (None, 32, 32, 16)   0           ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 32, 32, 16)   2304        ['re_lu_14[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 32, 32, 16)  64          ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_15 (ReLU)                (None, 32, 32, 16)   0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 32, 32, 16)   2304        ['re_lu_15[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 32, 32, 16)  64          ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 32, 32, 16)   0           ['batch_normalization_16[0][0]', \n",
      "                                                                  're_lu_14[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_16 (ReLU)                (None, 32, 32, 16)   0           ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 32, 32, 16)   2304        ['re_lu_16[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 32, 32, 16)  64          ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_17 (ReLU)                (None, 32, 32, 16)   0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 32, 32, 16)   2304        ['re_lu_17[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 32, 32, 16)  64          ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 32, 32, 16)   0           ['batch_normalization_18[0][0]', \n",
      "                                                                  're_lu_16[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_18 (ReLU)                (None, 32, 32, 16)   0           ['add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 16, 16, 32)   4608        ['re_lu_18[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 16, 16, 32)  128         ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_19 (ReLU)                (None, 16, 16, 32)   0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 16, 16, 32)   9216        ['re_lu_19[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 16, 16, 32)   512         ['re_lu_18[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 16, 16, 32)  128         ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 16, 16, 32)  128         ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 16, 16, 32)   0           ['batch_normalization_20[0][0]', \n",
      "                                                                  'batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_20 (ReLU)                (None, 16, 16, 32)   0           ['add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 16, 16, 32)   9216        ['re_lu_20[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 16, 16, 32)  128         ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_21 (ReLU)                (None, 16, 16, 32)   0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 16, 16, 32)   9216        ['re_lu_21[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 16, 16, 32)  128         ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 16, 16, 32)   0           ['batch_normalization_23[0][0]', \n",
      "                                                                  're_lu_20[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_22 (ReLU)                (None, 16, 16, 32)   0           ['add_10[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 16, 16, 32)   9216        ['re_lu_22[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 16, 16, 32)  128         ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_23 (ReLU)                (None, 16, 16, 32)   0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 16, 16, 32)   9216        ['re_lu_23[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 16, 16, 32)  128         ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 16, 16, 32)   0           ['batch_normalization_25[0][0]', \n",
      "                                                                  're_lu_22[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_24 (ReLU)                (None, 16, 16, 32)   0           ['add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 16, 16, 32)   9216        ['re_lu_24[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 16, 16, 32)  128         ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_25 (ReLU)                (None, 16, 16, 32)   0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 16, 16, 32)   9216        ['re_lu_25[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 16, 16, 32)  128         ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 16, 16, 32)   0           ['batch_normalization_27[0][0]', \n",
      "                                                                  're_lu_24[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_26 (ReLU)                (None, 16, 16, 32)   0           ['add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 16, 16, 32)   9216        ['re_lu_26[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 16, 16, 32)  128         ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_27 (ReLU)                (None, 16, 16, 32)   0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 16, 16, 32)   9216        ['re_lu_27[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 16, 16, 32)  128         ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 16, 16, 32)   0           ['batch_normalization_29[0][0]', \n",
      "                                                                  're_lu_26[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_28 (ReLU)                (None, 16, 16, 32)   0           ['add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 16, 16, 32)   9216        ['re_lu_28[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 16, 16, 32)  128         ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_29 (ReLU)                (None, 16, 16, 32)   0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 16, 16, 32)   9216        ['re_lu_29[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 16, 16, 32)  128         ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 16, 16, 32)   0           ['batch_normalization_31[0][0]', \n",
      "                                                                  're_lu_28[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_30 (ReLU)                (None, 16, 16, 32)   0           ['add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 16, 16, 32)   9216        ['re_lu_30[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 16, 16, 32)  128         ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_31 (ReLU)                (None, 16, 16, 32)   0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 16, 16, 32)   9216        ['re_lu_31[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 16, 16, 32)  128         ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 16, 16, 32)   0           ['batch_normalization_33[0][0]', \n",
      "                                                                  're_lu_30[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_32 (ReLU)                (None, 16, 16, 32)   0           ['add_15[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 16, 16, 32)   9216        ['re_lu_32[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 16, 16, 32)  128         ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_33 (ReLU)                (None, 16, 16, 32)   0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 16, 16, 32)   9216        ['re_lu_33[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 16, 16, 32)  128         ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_16 (Add)                   (None, 16, 16, 32)   0           ['batch_normalization_35[0][0]', \n",
      "                                                                  're_lu_32[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_34 (ReLU)                (None, 16, 16, 32)   0           ['add_16[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 16, 16, 32)   9216        ['re_lu_34[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 16, 16, 32)  128         ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_35 (ReLU)                (None, 16, 16, 32)   0           ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 16, 16, 32)   9216        ['re_lu_35[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 16, 16, 32)  128         ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_17 (Add)                   (None, 16, 16, 32)   0           ['batch_normalization_37[0][0]', \n",
      "                                                                  're_lu_34[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_36 (ReLU)                (None, 16, 16, 32)   0           ['add_17[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 8, 8, 64)     18432       ['re_lu_36[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 8, 8, 64)    256         ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_37 (ReLU)                (None, 8, 8, 64)     0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 8, 8, 64)     36864       ['re_lu_37[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 8, 8, 64)     2048        ['re_lu_36[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 8, 8, 64)    256         ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 8, 8, 64)    256         ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_18 (Add)                   (None, 8, 8, 64)     0           ['batch_normalization_39[0][0]', \n",
      "                                                                  'batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_38 (ReLU)                (None, 8, 8, 64)     0           ['add_18[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 8, 8, 64)     36864       ['re_lu_38[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 8, 8, 64)    256         ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_39 (ReLU)                (None, 8, 8, 64)     0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 8, 8, 64)     36864       ['re_lu_39[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 8, 8, 64)    256         ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_19 (Add)                   (None, 8, 8, 64)     0           ['batch_normalization_42[0][0]', \n",
      "                                                                  're_lu_38[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_40 (ReLU)                (None, 8, 8, 64)     0           ['add_19[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 8, 8, 64)     36864       ['re_lu_40[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 8, 8, 64)    256         ['conv2d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_41 (ReLU)                (None, 8, 8, 64)     0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 8, 8, 64)     36864       ['re_lu_41[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 8, 8, 64)    256         ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_20 (Add)                   (None, 8, 8, 64)     0           ['batch_normalization_44[0][0]', \n",
      "                                                                  're_lu_40[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_42 (ReLU)                (None, 8, 8, 64)     0           ['add_20[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 8, 8, 64)     36864       ['re_lu_42[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 8, 8, 64)    256         ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_43 (ReLU)                (None, 8, 8, 64)     0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 8, 8, 64)     36864       ['re_lu_43[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 8, 8, 64)    256         ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_21 (Add)                   (None, 8, 8, 64)     0           ['batch_normalization_46[0][0]', \n",
      "                                                                  're_lu_42[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_44 (ReLU)                (None, 8, 8, 64)     0           ['add_21[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 8, 8, 64)     36864       ['re_lu_44[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 8, 8, 64)    256         ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_45 (ReLU)                (None, 8, 8, 64)     0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 8, 8, 64)     36864       ['re_lu_45[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 8, 8, 64)    256         ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_22 (Add)                   (None, 8, 8, 64)     0           ['batch_normalization_48[0][0]', \n",
      "                                                                  're_lu_44[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_46 (ReLU)                (None, 8, 8, 64)     0           ['add_22[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 8, 8, 64)     36864       ['re_lu_46[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 8, 8, 64)    256         ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_47 (ReLU)                (None, 8, 8, 64)     0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 8, 8, 64)     36864       ['re_lu_47[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 8, 8, 64)    256         ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_23 (Add)                   (None, 8, 8, 64)     0           ['batch_normalization_50[0][0]', \n",
      "                                                                  're_lu_46[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_48 (ReLU)                (None, 8, 8, 64)     0           ['add_23[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 8, 8, 64)     36864       ['re_lu_48[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 8, 8, 64)    256         ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_49 (ReLU)                (None, 8, 8, 64)     0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 8, 8, 64)     36864       ['re_lu_49[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 8, 8, 64)    256         ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_24 (Add)                   (None, 8, 8, 64)     0           ['batch_normalization_52[0][0]', \n",
      "                                                                  're_lu_48[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_50 (ReLU)                (None, 8, 8, 64)     0           ['add_24[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 8, 8, 64)     36864       ['re_lu_50[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 8, 8, 64)    256         ['conv2d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_51 (ReLU)                (None, 8, 8, 64)     0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 8, 8, 64)     36864       ['re_lu_51[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 8, 8, 64)    256         ['conv2d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_25 (Add)                   (None, 8, 8, 64)     0           ['batch_normalization_54[0][0]', \n",
      "                                                                  're_lu_50[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_52 (ReLU)                (None, 8, 8, 64)     0           ['add_25[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 8, 8, 64)     36864       ['re_lu_52[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 8, 8, 64)    256         ['conv2d_55[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_53 (ReLU)                (None, 8, 8, 64)     0           ['batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 8, 8, 64)     36864       ['re_lu_53[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 8, 8, 64)    256         ['conv2d_56[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_26 (Add)                   (None, 8, 8, 64)     0           ['batch_normalization_56[0][0]', \n",
      "                                                                  're_lu_52[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_54 (ReLU)                (None, 8, 8, 64)     0           ['add_26[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 64)          0           ['re_lu_54[0][0]']               \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 3)            195         ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 859,571\n",
      "Trainable params: 855,315\n",
      "Non-trainable params: 4,256\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28d0706c-94e4-48ee-a9f5-3306d5e84463",
   "metadata": {},
   "outputs": [],
   "source": [
    "G=[[4],[11],[18],[25],[32],[39],[46],[53],[60],[1,7,14,21,28,35,42,49,56,63],\n",
    "   [67],[76],[83],[90],[97],[104],[111],[118],[125],[70,71,79,86,93,100,107,114,121,128],\n",
    "   [132],[141],[148],[155],[162],[169],[176],[183],[190],[135,136,144,151,158,165,172,179,186,193]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "906a2ac4-2607-4a63-9db4-8182bd3a3257",
   "metadata": {},
   "outputs": [],
   "source": [
    "P=[0,3,\n",
    "   6,10,13,17,20,24,27,31,34,38,41,45,48,52,55,59,62,66,\n",
    "   69,75,78,82,85,89,92,96,99,103,106,110,113,117,120,124,127,131,\n",
    "   134,140,143,147,150,154,157,161,164,168,171,175,178,182,185,189,192,196]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "564ea471-4e46-47bc-9d1f-e0d6df7de5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def JW(m, M):\n",
    "    \"\"\"\n",
    "    Compute the binary MD-LP J_w_value.\n",
    "\n",
    "    Args:\n",
    "        m: 1-D tensor of shape [d], the mean of the Minkowski difference of a \n",
    "           binary classification dataset.\n",
    "        M: 2-D tensor of shape [d, N], binary classification dataset Minkowski \n",
    "           difference set.\n",
    "           \n",
    "    Key idea:\n",
    "        - Calculate the approximate solution m_weighted for the optimal weights \n",
    "          in the MD-LP.\n",
    "        - Calculate the MD-LP based on the approximately optimal weights, and \n",
    "          perform a left truncation at 0.5. \n",
    "    Returns:\n",
    "        Binary MD-LP value.\n",
    "    \"\"\"\n",
    "    row_norm_sq = tf.reduce_sum(tf.square(M), axis=1)  \n",
    "    reciprocal_norm = tf.where(row_norm_sq != 0,\n",
    "                               tf.math.reciprocal(row_norm_sq),\n",
    "                               tf.zeros_like(row_norm_sq))  \n",
    "    m_weighted = m * reciprocal_norm  \n",
    "    m_weighted = tf.reshape(m_weighted, [1, -1])  \n",
    "    mM = tf.matmul(m_weighted, M)\n",
    "    L1 = tf.reduce_sum(mM)\n",
    "    L_1 = tf.reduce_sum(tf.abs(mM))\n",
    "    J_w_value = tf.abs(L1) / (L_1 + 1e-8)\n",
    "    J_w_value = tf.maximum(J_w_value, 0.5)\n",
    "    return J_w_value\n",
    "def W(X, Y, k, n_c=3):\n",
    "    \"\"\"\n",
    "    This function is used to calculate the top k largest binary classification \n",
    "    problems MD-LP used in the multi-classification problem calculation. Here, \n",
    "    the binary classification problems are obtained by combining each pair of \n",
    "    categories of the multi-classification problem.\n",
    "    Args:\n",
    "        X: Tensor/array of shape [b, l, w]. Channel output.\n",
    "        Y: Tensor/array of labels of shape [b]. Data labels.\n",
    "        k: Number of the largest binary MD-LP to keep.\n",
    "        n_c: Number of classes.\n",
    "    Returns:\n",
    "        JK_list: Tensor of shape [k], the top-k MD-LP.\n",
    "    \"\"\"\n",
    "    b, l, w = X.shape\n",
    "    X = tf.reshape(X, [b, l*w])   # flatten\n",
    "    J_list = []\n",
    "    for i, j in itertools.combinations(range(n_c), 2):\n",
    "        mask_1 = tf.reshape(tf.equal(Y, i), [-1])\n",
    "        mask_2 = tf.reshape(tf.equal(Y, j), [-1])\n",
    "        X1 = tf.boolean_mask(X, mask_1)\n",
    "        X2 = tf.boolean_mask(X, mask_2)\n",
    "        n1 = tf.shape(X1)[0]\n",
    "        n2 = tf.shape(X2)[0]\n",
    "        m_i = tf.reduce_sum(X1, axis=0) * tf.cast(n2, tf.float32) - tf.reduce_sum(X2, axis=0) * tf.cast(n1, tf.float32)\n",
    "        M_i = tf.reshape(X1[:, None, :] - X2[None, :, :], [-1, l*w])\n",
    "        M_i = tf.transpose(M_i)\n",
    "        J = JW(m_i, M_i)\n",
    "        J_list.append(J)\n",
    "    J_list = tf.stack(J_list)\n",
    "    JK_list , JK_inde = tf.math.top_k(J_list,k)\n",
    "    return JK_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "779631d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L1_channel(x_L,y,prune_rate, nnn, alpha=2.5):\n",
    "    \"\"\"\n",
    "    This function computes TCR measure of each channel in convolutional layer.\n",
    "    \n",
    "    Given the output of a convolutional layer, this function will execute:\n",
    "    - Treating each channel independently and computing a multi-class MD-LP \n",
    "      via function W;\n",
    "    - By applying nonlinear transformation, a TCR measure is constructed \n",
    "      to enhance the separability of MD-LP.\n",
    "    \n",
    "    Key Args:\n",
    "    x_L (Tensor):\n",
    "        Output of a convolutional hidden layer, with shape \n",
    "        [batch_size, height, width, channels].\n",
    "    y (Tensor):\n",
    "        Ground-truth labels corresponding to the input samples.\n",
    "    alpha (float, optional):\n",
    "        LP transformation parameter. Used to enhance the separability \n",
    "        of the MD-LP close to 1.\n",
    "    \n",
    "    Returns:\n",
    "    jw:\n",
    "        TCR measure of each channel.\n",
    "    \"\"\"\n",
    "    a, b, d, c = x_L.shape\n",
    "    jw = tf.zeros([c], dtype=tf.float32)\n",
    "    alpha = tf.cast(alpha, tf.float32)\n",
    "    for j in tf.range(c):\n",
    "        N_tf = W(x_L[:,:,:,j], y, nnn)\n",
    "        jw_j = tf.norm(N_tf) / tf.sqrt(float(nnn))\n",
    "        jw_j = (tf.exp(alpha * (2*jw_j-1)) - 1.0) / (tf.exp(alpha) - 1.0)\n",
    "        jw = tf.tensor_scatter_nd_update(jw, [[j]], [jw_j])\n",
    "    return jw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2acfaba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_channel(x_LG, y, prune_rate, nnn=3, esp=1e-8):\n",
    "    \"\"\"\n",
    "    This function computes the structural redundancy evaluation criterion R_L \n",
    "    and determines the set of retained channel indices `channel_i_label` used \n",
    "    by the pruning algorithm for a layer group.\n",
    "    \n",
    "    Given the output of a convolutional layer, this function will execute:\n",
    "    - By analyzing the propensity calculation of TCR measure, an evaluation \n",
    "      criterion for evaluating the redundancy of convolutional layers is derived.\n",
    "    - Based on the TCR measure, the pruning threshold is calculated and the \n",
    "      channels that remain after pruning are selected.\n",
    "    \n",
    "    Key Args:\n",
    "    x_LG (a list of Tensors):\n",
    "        Output of a group of convolutional hidden layers.\n",
    "    y (Tensor):\n",
    "        Ground-truth labels corresponding to the input samples.\n",
    "    prune_rate (float):\n",
    "        Pruning parameter. Used to control the strictness of pruning.\n",
    "    \n",
    "    Returns:\n",
    "    channel_i_label (ndarray):\n",
    "        Indices of channels retained after pruning.\n",
    "    R_L (float):\n",
    "        Structural redundancy evaluation criterion of the layer group,\n",
    "    \"\"\"\n",
    "    a, b, d, c = x_LG[-1].shape\n",
    "    L1_list = []\n",
    "    for i in range(len(x_LG)):\n",
    "        L1_i = L1_channel(x_LG[i], y, prune_rate, nnn)\n",
    "        L1_list.append(L1_i)\n",
    "    L1 = tf.stack(L1_list, axis=0)  # shape: (len(x_LG), c)\n",
    "    jw = tf.reduce_mean(L1, axis=0) # shape: (c,)\n",
    "    jw_min = tf.maximum(tf.reduce_min(jw) - esp, 0.0)\n",
    "    jw_max = tf.reduce_max(jw)\n",
    "    me = tf.sqrt(tf.reduce_mean(tf.square(jw - jw_min)))\n",
    "    jd = jw_min + prune_rate * me\n",
    "    mean = tf.maximum(tf.reduce_mean(jw) - esp, 0.0)\n",
    "    R_L = tf.reduce_mean(tf.sign(jw - mean))\n",
    "    channel_i_label = tf.where(jw >= jd)[:,0]\n",
    "    return channel_i_label.numpy(), R_L.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62555afb-03be-491e-a73b-8a314b2941ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Group_1(x_L,w,S):\n",
    "    \"\"\"This function is used to collect the key hidden layer outputs of the first block \n",
    "    in ResNet. Here, x_L1 is used to update the list of output from the ResNet \n",
    "    convolutional layers, and x_L2 is used to provide the hidden layer outputs required \n",
    "    for layer group pruning.\"\"\"\n",
    "    wb=w[0]\n",
    "    bn=w[1]\n",
    "    x_L1=[]\n",
    "    x_L2=[]\n",
    "    x_1=layer_xL(\"conv2d\",x_L,w=wb[0])\n",
    "    x_1=layer_xL(\"batch_normalization\",x_1,w=bn[0])\n",
    "    x_1=layer_xL(\"activation\",x_1)\n",
    "    x_L2.append(deepcopy(x_1))\n",
    "    #x_1=layer_xL(\"maxpooling\",x_1)\n",
    "    x_L1.append(deepcopy(x_1))\n",
    "\n",
    "    for i in range(9):\n",
    "        \n",
    "        x_2=layer_xL(\"conv2d\",x_1,w=wb[2*i+1])\n",
    "        x_2=layer_xL(\"batch_normalization\",x_2,w=bn[2*i+1])\n",
    "        x_2=layer_xL(\"activation\",x_2)\n",
    "        x_L1.append(deepcopy(x_2))\n",
    "        \n",
    "        x_2=layer_xL(\"conv2d\",x_2,w=wb[2*i+2])\n",
    "        x_2=layer_xL(\"batch_normalization\",x_2,w=bn[2*i+2])\n",
    "        x_1=layer_xL(\"add\",[x_2,x_1])\n",
    "        x_1=layer_xL(\"activation\",x_1)\n",
    "        x_L1.append(deepcopy(x_1))\n",
    "        x_L2.append(deepcopy(x_1))\n",
    "    return x_L1,x_L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b224b60b-5f03-4f1d-9d30-287e9dcc8aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Group_L(x_L,w,S):\n",
    "    \"\"\"This function is used to collect the key hidden layer outputs of the other block \n",
    "    in ResNet. Here, x_L1 is used to update the list of output from the ResNet \n",
    "    convolutional layers, and x_L2 is used to provide the hidden layer outputs required \n",
    "    for layer group pruning.\"\"\"\n",
    "    wb=w[0]\n",
    "    bn=w[1]\n",
    "    x_L1=[]\n",
    "    x_L2=[]\n",
    "    x_1=layer_xL(\"conv2d\",x_L,w=wb[0],S=2)\n",
    "    x_1=layer_xL(\"batch_normalization\",x_1,w=bn[0])\n",
    "    x_1=layer_xL(\"activation\",x_1)\n",
    "    x_L1.append(deepcopy(x_1))\n",
    "            \n",
    "    x_1=layer_xL(\"conv2d\",x_1,w=wb[1])\n",
    "    x_2=layer_xL(\"conv2d\",x_L,w=wb[2],S=2)\n",
    "    x_1=layer_xL(\"batch_normalization\",x_1,w=bn[1])\n",
    "    x_2=layer_xL(\"batch_normalization\",x_2,w=bn[2])\n",
    "    x_1=layer_xL(\"add\",[x_1,x_2])\n",
    "    x_1=layer_xL(\"activation\",x_1)\n",
    "    x_L1.append(deepcopy(x_1))\n",
    "    x_L2.append(deepcopy(x_1))\n",
    "\n",
    "    for i in range(8):\n",
    "        \n",
    "        x_2=layer_xL(\"conv2d\",x_1,w=wb[2*i+3])\n",
    "        x_2=layer_xL(\"batch_normalization\",x_2,w=bn[2*i+3])\n",
    "        x_2=layer_xL(\"activation\",x_2)\n",
    "        x_L1.append(deepcopy(x_2))\n",
    "    \n",
    "        x_2=layer_xL(\"conv2d\",x_2,w=wb[2*i+4])\n",
    "        x_2=layer_xL(\"batch_normalization\",x_2,w=bn[2*i+4])\n",
    "        x_1=layer_xL(\"add\",[x_2,x_1])\n",
    "        x_1=layer_xL(\"activation\",x_1)\n",
    "        x_L1.append(deepcopy(x_1))\n",
    "        x_L2.append(deepcopy(x_1))\n",
    "    return x_L1,x_L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b348156b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_xL(layer_name,x_L,w=None,F=False,S=1):\n",
    "    \"\"\"This function is used to obtain the outputs of various hidden layers or layer groups in the \n",
    "    network, which is utilized for updating the outputs of hidden layers or for performing layer \n",
    "    group pruning calculations.\"\"\"\n",
    "    if \"conv2d\" in layer_name:\n",
    "        weight=w[0]\n",
    "        strides=[1,S,S,1]\n",
    "        x_L1=tf.nn.conv2d(x_L,weight,strides=strides,padding=\"SAME\")\n",
    "        #x_L1=tf.nn.bias_add(x_L1,bias)\n",
    "        return x_L1\n",
    "    if \"first\" in layer_name:\n",
    "        x_L1,x_L2=Group_1(x_L,w,S)\n",
    "        if F==True:\n",
    "            return x_L2\n",
    "        else:\n",
    "            return x_L1\n",
    "    if \"group\" in layer_name:\n",
    "        x_L1,x_L2=Group_L(x_L,w,S)\n",
    "        if F==True:\n",
    "            return x_L2\n",
    "        else:\n",
    "            return x_L1\n",
    "    if \"batch_normalization\" in layer_name:\n",
    "        gamma,beta,mean,var=w\n",
    "        x_L1=tf.nn.batch_normalization(x_L,mean=mean,\n",
    "                                          variance=var,\n",
    "                                          offset=beta,\n",
    "                                          scale=gamma,variance_epsilon=1e-5)\n",
    "        return x_L1\n",
    "    if \"activation\" in layer_name:\n",
    "        x_L1=tf.nn.relu(x_L)\n",
    "        return x_L1\n",
    "    if \"add\" in layer_name:\n",
    "        x1,x2=x_L\n",
    "        x_L1=tf.math.add(x1,x2)\n",
    "        return x_L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "355a0370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_block(a,b,G,weight_list,x_LG,First=False,Group=False,R=False,F=False):\n",
    "    \"\"\"This function is used to update the list of hidden layer outputs \n",
    "    of ResNet after function pruning. For single-hidden-layer pruning, \n",
    "    it only needs to update the output of the convolutional layer within \n",
    "    the block. However, for layer group pruning, since it involves multiple \n",
    "    blocks, the output of all convolutional layers in these blocks needs \n",
    "    to be updated.\"\"\"\n",
    "    if Group==False:\n",
    "        if R==True:\n",
    "            x_1=x_LG[b]\n",
    "            layer_l=G[a][0]\n",
    "            wc=weight_list[layer_l]\n",
    "            wb=weight_list[layer_l+1]\n",
    "            x_2=layer_xL(\"conv2d\",x_1,wc,S=2)\n",
    "            x_2=layer_xL(\"batch_normalization\",x_2,wb)\n",
    "            x_2=layer_xL(\"activation\",x_2)\n",
    "            x_LG[b+1]=x_2\n",
    "            layer_l=G[a+9][0]\n",
    "            wc=weight_list[layer_l]\n",
    "            wb=weight_list[layer_l+2]\n",
    "            x_2=layer_xL(\"conv2d\",x_2,wc)\n",
    "            x_2=layer_xL(\"batch_normalization\",x_2,wb)\n",
    "            layer_l=G[a+9][1]\n",
    "            wc=weight_list[layer_l]\n",
    "            wb=weight_list[layer_l+2]\n",
    "            x_1=layer_xL(\"conv2d\",x_1,wc,S=2)\n",
    "            x_1=layer_xL(\"batch_normalization\",x_1,wb)\n",
    "            x_1=layer_xL(\"add\",[x_2,x_1])\n",
    "            x_1=layer_xL(\"activation\",x_1)\n",
    "            x_LG[b+2]=x_1\n",
    "            return x_LG\n",
    "        if R==False:\n",
    "            x_1=x_LG[b]\n",
    "            layer_l=G[a][0]\n",
    "            wc=weight_list[layer_l]\n",
    "            wb=weight_list[layer_l+1]\n",
    "            x_2=layer_xL(\"conv2d\",x_1,wc)\n",
    "            x_2=layer_xL(\"batch_normalization\",x_2,wb)\n",
    "            x_2=layer_xL(\"activation\",x_2)\n",
    "            x_LG[b+1]=x_2\n",
    "            if First==True:\n",
    "                layer_l=G[a+9][1]\n",
    "            else:\n",
    "                aaa=int(((a+1)//10+1)*10)\n",
    "                layer_l=G[aaa-1][a%10+1]\n",
    "            wc=weight_list[layer_l]\n",
    "            wb=weight_list[layer_l+1]\n",
    "            x_2=layer_xL(\"conv2d\",x_2,wc)\n",
    "            x_2=layer_xL(\"batch_normalization\",x_2,wb)\n",
    "            x_1=layer_xL(\"add\",[x_2,x_1])\n",
    "            x_1=layer_xL(\"activation\",x_1)\n",
    "            x_LG[b+2]=x_1\n",
    "            return x_LG\n",
    "    if Group==True:\n",
    "        if First==True:\n",
    "            label=[G[a][0],G[a-9][0],G[a][1],G[a-8][0],G[a][2],G[a-7][0],G[a][3],G[a-6][0],G[a][4],G[a-5][0],G[a][5],G[a-4][0],G[a][6]\n",
    "                  ,G[a-3][0],G[a][7],G[a-2][0],G[a][8],G[a-1][0],G[a][9]]\n",
    "            w1=[]\n",
    "            w2=[]\n",
    "            x_1=x_LG[b]\n",
    "            for i in range(19):\n",
    "                w1.append(weight_list[label[i]])\n",
    "                w2.append(weight_list[label[i]+1])\n",
    "            w=[w1,w2]\n",
    "            x_1=layer_xL(\"first\",x_1,w,F=False,S=1)\n",
    "            for i in range(19):\n",
    "                x_LG[b+i+1]=x_1[i]\n",
    "            return x_LG\n",
    "        else:\n",
    "            label=[G[a-9][0],G[a][0],G[a][1],G[a-8][0],G[a][2],G[a-7][0],G[a][3],G[a-6][0],G[a][4],G[a-5][0],G[a][5],G[a-4][0],G[a][6]\n",
    "                  ,G[a-3][0],G[a][7],G[a-2][0],G[a][8],G[a-1][0],G[a][9]]\n",
    "            w1=[]\n",
    "            w2=[]\n",
    "            x_1=x_LG[b]\n",
    "            l=[1,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]\n",
    "            for i in range(19):\n",
    "                w1.append(weight_list[label[i]])\n",
    "                w2.append(weight_list[label[i]+l[i]])\n",
    "            w=[w1,w2]\n",
    "            x_1=layer_xL(\"group\",x_1,w)\n",
    "            for i in range(18):\n",
    "                x_LG[b+i+1]=x_1[i]\n",
    "            return x_LG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4ac50a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x(a,b,G,x_LG,weight_list,First=False):\n",
    "    \"\"\"This function is used to provide the required output list \n",
    "    for 'prune_channel' function when performing layer group pruning.\"\"\"\n",
    "    x_l=x_LG[b]\n",
    "    if First==True:\n",
    "        label=[G[a][0],G[a-9][0],G[a][1],G[a-8][0],G[a][2],G[a-7][0],G[a][3],G[a-6][0],G[a][4],G[a-5][0],G[a][5],G[a-4][0],G[a][6]\n",
    "               ,G[a-3][0],G[a][7],G[a-2][0],G[a][8],G[a-1][0],G[a][9]]\n",
    "    else:\n",
    "        label=[G[a-9][0],G[a][0],G[a][1],G[a-8][0],G[a][2],G[a-7][0],G[a][3],G[a-6][0],G[a][4],G[a-5][0],G[a][5],G[a-4][0],G[a][6]\n",
    "               ,G[a-3][0],G[a][7],G[a-2][0],G[a][8],G[a-1][0],G[a][9]]\n",
    "    w1=[]\n",
    "    w2=[]\n",
    "    for i in range(19):\n",
    "        w1.append(weight_list[label[i]])\n",
    "    l=[1,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]\n",
    "    if First==True:\n",
    "        for i in range(19):\n",
    "            w2.append(weight_list[label[i]+1])\n",
    "        w=[w1,w2]\n",
    "        x_L=layer_xL('first',x_l,w,F=True)\n",
    "    else:\n",
    "        for i in range(19):\n",
    "            w2.append(weight_list[label[i]+l[i]])\n",
    "        w=[w1,w2]\n",
    "        x_L=layer_xL('group',x_l,w,F=True)\n",
    "    return x_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f4a2f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_model(model,G,P,x,y,prune_rate,q=198):\n",
    "    \"\"\"\n",
    "    Structured Channel Group Pruning Function Based on MD-LP (Channel-wise Pruning) \n",
    "    \n",
    "    This function is the main function for pruning in ResNet-56. It achieves \n",
    "    the pruning of layer groups by using the provided convolution layer groups G.\n",
    "    The main process of this function is as follows:\n",
    "    - Pruning Preparation: Based on the hidden layer positions provided by P, \n",
    "      construct the input/output lists for the pruning-required convolutional layers, \n",
    "      as well as the list of convolution kernel parameters and BN layer parameters.\n",
    "    - Layer Group Pruning: In accordance with the sequence in G, the pruning_channel \n",
    "      function is used to perform pruning successively, resulting in the channels \n",
    "      that are retained after pruning, which are labeled as channel_new_label.\n",
    "    - Output/Parameter Update: Based on the channel_new_label, the parameters of the \n",
    "      convolutional layers included in the group, as well as the parameters of the \n",
    "      convolutional layers whose outputs are used as inputs, are updated. And the \n",
    "      input/output lists of the convolutional layers are updated according to the \n",
    "      updated parameters.\n",
    "    \n",
    "    Input:\n",
    "    model : Original Keras ResNet-18\n",
    "    x : Network input samples (used for forward propagation and channel evaluation)\n",
    "    y : Sample labels (used for metric calculation in prune_channel)\n",
    "    prune_rate : Pruning parameter\n",
    "    G : The grouped list of network convolution layers, based on the ReNet network \n",
    "    structure, divides the hidden layers of ResNet. It is used to ensure that the \n",
    "    output results of the network hidden layers within the same group after pruning \n",
    "    can still maintain the same size and can be added together.\n",
    "    \n",
    "    Output:\n",
    "    weight_list: List of weights for each convolutional / BN layer after pruning.\n",
    "    channel_label: Record of the number of retained channels for each layer group.   \n",
    "    \"\"\"\n",
    "    layer_outputs =[layer.output for layer in model.layers] \n",
    "    weight_list=[]\n",
    "    # =========================\n",
    "    # Collect the input/output of the convolutional layers, and the parameters\n",
    "    # of the convolutional layers and BN layers in the ResNet network.\n",
    "    # =========================\n",
    "    for i in range(q+1):\n",
    "        layer=model.layers[i]\n",
    "        if \"conv\" in layer.name:\n",
    "            w=layer.get_weights()\n",
    "            weight_list.append(w)\n",
    "            #print(i)\n",
    "        elif \"dense\" in layer.name:\n",
    "            w,b=layer.get_weights()\n",
    "            weight_list.append([w,b])\n",
    "        elif \"batch_normalization\" in layer.name:\n",
    "            g,b,m,v=layer.get_weights()\n",
    "            weight_list.append([g,b,m,v])\n",
    "        else:\n",
    "            weight_list.append(None)\n",
    "    x_LG=[]\n",
    "    for i in range(len(P)):\n",
    "        activation_model = tf.keras.models.Model(inputs=model.input,outputs=layer_outputs[P[i]])\n",
    "        layer_x=activation_model.predict(x)\n",
    "        x_LG.append(layer_x)\n",
    "    channel_label=[]\n",
    "    b=1\n",
    "    for i in range(len(G)):\n",
    "        if len(G[i])==1:\n",
    "            # =========================\n",
    "            # According to the prune_channel function, the single convolution layer in G is pruned, \n",
    "            # resulting in the retained channels after pruning. Based on the pruning results, the \n",
    "            # network parameters and network input/output are updated.\n",
    "            # =========================\n",
    "            if (b-1)%18==0:\n",
    "                a=G[i][0]\n",
    "                channel_new_label,r_L=prune_channel([x_LG[b+1]],y,prune_rate)\n",
    "                print(len(channel_new_label),0)\n",
    "                #print(weight_list[a][0].shape)\n",
    "                weight_list[a][0]=weight_list[a][0][:,:,:,channel_new_label]\n",
    "                #weight_list[a][1]=weight_list[a][1][channel_new_label]\n",
    "                for j in range(4):\n",
    "                    weight_list[a+1][j]=weight_list[a+1][j][channel_new_label]\n",
    "                if i==0:\n",
    "                    a1=G[i+9][1]\n",
    "                    weight_list[a1][0]=weight_list[a1][0][:,:,channel_new_label,:]\n",
    "                    x_LG=x_block(i,b,G,weight_list,x_LG,First=True)\n",
    "                else:\n",
    "                    a1=G[i+9][0]\n",
    "                    weight_list[a1][0]=weight_list[a1][0][:,:,channel_new_label,:]\n",
    "                    x_LG=x_block(i,b,G,weight_list,x_LG,First=False,R=True)\n",
    "                channel_label.append(len(channel_new_label))\n",
    "                b+=2\n",
    "                continue\n",
    "            else:\n",
    "                a=G[i][0]\n",
    "                aaa=int(((i+1)//10+1)*10)\n",
    "                channel_new_label,r_L=prune_channel([x_LG[b+1]],y,prune_rate)\n",
    "                print(len(channel_new_label),1)\n",
    "                weight_list[a][0]=weight_list[a][0][:,:,:,channel_new_label]\n",
    "                #weight_list[a][1]=weight_list[a][1][channel_new_label]\n",
    "                for j in range(4):\n",
    "                    weight_list[a+1][j]=weight_list[a+1][j][channel_new_label]\n",
    "                channel_label.append(len(channel_new_label))\n",
    "                a1=G[aaa-1][i%10+1]\n",
    "                weight_list[a1][0]=weight_list[a1][0][:,:,channel_new_label,:]\n",
    "                x_LG=x_block(i,b,G,weight_list,x_LG)\n",
    "                if (b-1)%18==16:\n",
    "                    if i==8:\n",
    "                        b-=17\n",
    "                    else:\n",
    "                        b-=16\n",
    "                else:\n",
    "                    b+=2\n",
    "                continue\n",
    "        if len(G[i])>1:\n",
    "            # =========================\n",
    "            # According to the prune_channel function, the layer group in G with multiple convolutional \n",
    "            # layers is pruned to obtain a unified set of pruned channels. Based on the pruning results, \n",
    "            # the network parameters and network input/output are updated.\n",
    "            # =========================\n",
    "            if i==9:\n",
    "                x_LP=get_x(i,b,G,x_LG,weight_list,First=True)\n",
    "            else:\n",
    "                x_LP=get_x(i,b,G,x_LG,weight_list)\n",
    "            channel_new_label,r_L=prune_channel(x_LP,y,prune_rate)\n",
    "            print(len(channel_new_label),2)\n",
    "            for g in G[i]:\n",
    "                weight_list[g][0]=weight_list[g][0][:,:,:,channel_new_label]\n",
    "                #weight_list[g][1]=weight_list[g][1][channel_new_label]\n",
    "            for j in range(8):\n",
    "                weight_list[G[i-8+j][0]][0]=weight_list[G[i-8+j][0]][0][:,:,channel_new_label,:]\n",
    "            if i==9:\n",
    "                for g in G[i]:\n",
    "                    for j in range(4):\n",
    "                        weight_list[g+1][j]=weight_list[g+1][j][channel_new_label]\n",
    "                weight_list[G[i-9][0]][0]=weight_list[G[i-9][0]][0][:,:,channel_new_label,:]\n",
    "            else:\n",
    "                l=[2,2,1,1,1,1,1,1,1,1]\n",
    "                for g in range(10):\n",
    "                    for j in range(4):\n",
    "                        weight_list[G[i][g]+l[g]][j]=weight_list[G[i][g]+l[g]][j][channel_new_label]\n",
    "            if i!=len(G)-1:\n",
    "                weight_list[G[i+1][0]][0]=weight_list[G[i+1][0]][0][:,:,channel_new_label,:]\n",
    "                weight_list[G[i+10][1]][0]=weight_list[G[i+10][1]][0][:,:,channel_new_label,:]\n",
    "            if i==9:\n",
    "                x_LG=x_block(i,b,G,weight_list,x_LG,First=True,R=False,Group=True)\n",
    "                b+=19\n",
    "            else:\n",
    "                x_LG=x_block(i,b,G,weight_list,x_LG,First=False,R=False,Group=True)\n",
    "                b+=18\n",
    "            channel_label.append(len(channel_new_label))\n",
    "            continue\n",
    "    weight_list[q][0]=weight_list[q][0][channel_new_label]\n",
    "    return weight_list,channel_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2428f648-7af9-4278-8686-5024da702c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pr(model,weight_list,channel_label):\n",
    "    \"\"\"This function is used to construct a pruned network by using \n",
    "    the given pruned network structure and parameters.\"\"\"\n",
    "    model_p=Res_model(channel_label)\n",
    "    for i in range(len(weight_list)):\n",
    "        if weight_list[i]!=None:\n",
    "            w = [ww for ww in weight_list[i]]\n",
    "            model_p.layers[i].set_weights(w)\n",
    "    return model_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c451b93e-3b25-44cf-b461-e4edd32e51c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "            samplewise_center=False,  # set each sample mean to 0\n",
    "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "            samplewise_std_normalization=False,  # divide each input by its std\n",
    "            zca_whitening=False,  # apply ZCA whitening\n",
    "            rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "            height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "            horizontal_flip=True,  # randomly flip images\n",
    "            vertical_flip=False)  # randomly flip images\n",
    "        # (std, mean, and principal components if ZCA whitening is applied).\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d9dd391",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrain(model,x_train,y_train,x_test,y_test):\n",
    "    \"\"\"This function is used to fine-tune the pruned network \n",
    "    using the same method as the original network training.\"\"\"\n",
    "    total_steps = epochs * (x_train.shape[0] // batch_size)\n",
    "    warmup_steps = warmup_epochs * (x_train.shape[0] // batch_size)\n",
    "    lr_schedule = WarmUpCosine(initial_lr, total_steps, warmup_steps)\n",
    "    optimizer = CustomWeightDecaySGD(weight_decay=weight_decay,learning_rate=lr_schedule,momentum=0.9,nesterov=True)\n",
    "    loss_fn=tf.keras.losses.CategoricalCrossentropy()\n",
    "    model.compile(optimizer=optimizer,loss=loss_fn,metrics=['accuracy'])\n",
    "    saver = LastNSaver(n=20)\n",
    "    model.fit(datagen.flow(x_train, y_train_onehot,batch_size=batch_size),\n",
    "                            steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                            epochs=epochs,\n",
    "                            validation_data=(x_test, y_test_onehot),verbose=2,callbacks=[saver])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34c12c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"These functions are used to calculate the FLOPs \n",
    "and the number of parameters of the network.\"\"\"\n",
    "def conv_flops_params(layer, input_shape):\n",
    "    h_in, w_in, cin = input_shape[1:]\n",
    "    h_out, w_out, cout = layer.output_shape[1:]\n",
    "    k_h, k_w = layer.kernel_size\n",
    "    flops = h_out * w_out * cin * cout * k_h * k_w\n",
    "    params = cin * cout * k_h * k_w\n",
    "    if layer.use_bias:\n",
    "        params += cout\n",
    "    return flops, params, (h_out, w_out, cout)\n",
    "def dense_flops_params(layer, input_shape):\n",
    "    cin = input_shape[-1]\n",
    "    cout = layer.units\n",
    "    flops = cin * cout\n",
    "    params = cin * cout\n",
    "    if layer.use_bias:\n",
    "        params += cout\n",
    "    return flops, params, (cout,)\n",
    "def compute_flops_params(model, input_shape=(32, 32, 3)):\n",
    "    total_flops = 0\n",
    "    total_params = 0\n",
    "    dummy_input = tf.zeros((1, *input_shape))\n",
    "    _ = model(dummy_input)\n",
    "    current_shape = (1, *input_shape)\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "            flops, params, out_shape = conv_flops_params(layer, current_shape)\n",
    "            total_flops += flops\n",
    "            total_params += params\n",
    "            current_shape = (1, *out_shape)\n",
    "        elif isinstance(layer, tf.keras.layers.Dense):\n",
    "            flops, params, out_shape = dense_flops_params(layer, current_shape)\n",
    "            total_flops += flops\n",
    "            total_params += params\n",
    "            current_shape = (1, *out_shape)\n",
    "    return total_flops, total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c45c7e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def R_layers(model,x,y,R=P[1:]):\n",
    "    \"\"\"This function is used to obtain the structural redundancy \n",
    "    criterion of each block in the ResNet-18 network.\"\"\"\n",
    "    layer_outputs =[layer.output for layer in model.layers] \n",
    "    R_L=[]\n",
    "    channel_label=[]\n",
    "    for i in range(len(R)):\n",
    "        print('start')\n",
    "        activation_model = tf.keras.models.Model(inputs=model.input,outputs=layer_outputs[R[i]])\n",
    "        x_L=activation_model.predict(x)\n",
    "        #x_L=layer_x[R[i]]\n",
    "        #print(x_L)\n",
    "        channel_new_label,r_L=prune_channel([x_L],y,0,nnn=2)\n",
    "        r_L=float(r_L)\n",
    "        print('finish')\n",
    "        R_L.append(r_L)\n",
    "        print(r_L)\n",
    "    R_L=np.array(R_L)\n",
    "    LLL=[1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2]\n",
    "    RR_L=[]\n",
    "    iii=0\n",
    "    for k in range(len(LLL)):\n",
    "        if LLL[k]==1:\n",
    "            RR_L.append(R_L[0])\n",
    "        if LLL[k]==2:\n",
    "            RR_L.append(R_L[iii:iii+2].sum()/2)\n",
    "        iii+=LLL[k]\n",
    "    return R_L,RR_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "590d84b3-a696-4d89-aea1-bfbc1f329efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_G(model):\n",
    "    \"\"\"This function is used to obtain the number of channels of the layer group.\"\"\"\n",
    "    C=[]\n",
    "    for i in range(len(G)):\n",
    "        CG=0\n",
    "        for g in G[i]:\n",
    "            a,b,d,c=model.layers[g].output.shape\n",
    "            CG+=c\n",
    "        C.append(CG)\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fedc74ac-8c3e-45d0-b7e7-7c172ca91b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 2s 16ms/step - loss: 0.2077 - accuracy: 0.9463\n",
      "126009536\n"
     ]
    }
   ],
   "source": [
    "P_list=[]\n",
    "E_list=[]\n",
    "F_list=[]\n",
    "#RP_list=[]\n",
    "#RRP_list=[]\n",
    "C_list=[]\n",
    "flops,par=compute_flops_params(model)\n",
    "loss, acc = model.evaluate(x_test, y_test_onehot)\n",
    "C_0=channel_G(model)\n",
    "print(flops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "53af22f6-df8c-4957-a688-41c83f207426",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_FILE = \"training_ResNet56_dist_log.json\"\n",
    "def load_progress():\n",
    "    if os.path.exists(SAVE_FILE):\n",
    "        with open(SAVE_FILE, \"r\") as f:\n",
    "            return json.load(f)\n",
    "    return {\"results\": [], \n",
    "            \"RR_L\": [],\n",
    "            \"P_list\": [],\n",
    "            \"E_list\": [],\n",
    "            \"F_list\": [],\n",
    "            \"C_list\": [],\n",
    "            \"last_lam_idx\": 0,\n",
    "            \"last_repeat\": 0,\n",
    "            \"RL_exist\": 0,\n",
    "            \"Cri_exist\": 0}\n",
    "def save_progress(progress):\n",
    "    with open(SAVE_FILE, \"w\") as f:\n",
    "        json.dump(progress, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "63480be8-495b-42d6-bf58-f8cdbc6a810f",
   "metadata": {},
   "outputs": [],
   "source": [
    "progress = load_progress()\n",
    "start_lr_idx = progress[\"last_lam_idx\"]\n",
    "start_repeat = progress[\"last_repeat\"]\n",
    "If_RL = progress[\"RL_exist\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "166ebc0f-0461-4284-ba93-750a5b8f4c49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "finish\n",
      "0.0\n",
      "start\n",
      "finish\n",
      "-0.125\n",
      "start\n",
      "finish\n",
      "0.125\n",
      "start\n",
      "finish\n",
      "-0.125\n",
      "start\n",
      "finish\n",
      "-0.375\n",
      "start\n",
      "finish\n",
      "0.0\n",
      "start\n",
      "finish\n",
      "-0.25\n",
      "start\n",
      "finish\n",
      "0.125\n",
      "start\n",
      "finish\n",
      "0.0\n",
      "start\n",
      "finish\n",
      "-0.125\n",
      "start\n",
      "finish\n",
      "-0.125\n",
      "start\n",
      "finish\n",
      "0.0\n",
      "start\n",
      "finish\n",
      "0.125\n",
      "start\n",
      "finish\n",
      "0.0\n",
      "start\n",
      "finish\n",
      "0.125\n",
      "start\n",
      "finish\n",
      "0.125\n",
      "start\n",
      "finish\n",
      "0.25\n",
      "start\n",
      "finish\n",
      "0.0\n",
      "start\n",
      "finish\n",
      "0.125\n",
      "start\n",
      "finish\n",
      "0.125\n",
      "start\n",
      "finish\n",
      "-0.0625\n",
      "start\n",
      "finish\n",
      "0.0625\n",
      "start\n",
      "finish\n",
      "0.125\n",
      "start\n",
      "finish\n",
      "0.1875\n",
      "start\n",
      "finish\n",
      "-0.0625\n",
      "start\n",
      "finish\n",
      "0.0\n",
      "start\n",
      "finish\n",
      "0.0625\n",
      "start\n",
      "finish\n",
      "0.1875\n",
      "start\n",
      "finish\n",
      "0.0625\n",
      "start\n",
      "finish\n",
      "0.125\n",
      "start\n",
      "finish\n",
      "0.0\n",
      "start\n",
      "finish\n",
      "0.125\n",
      "start\n",
      "finish\n",
      "0.125\n",
      "start\n",
      "finish\n",
      "0.0625\n",
      "start\n",
      "finish\n",
      "-0.0625\n",
      "start\n",
      "finish\n",
      "0.125\n",
      "start\n",
      "finish\n",
      "-0.1875\n",
      "start\n",
      "finish\n",
      "0.09375\n",
      "start\n",
      "finish\n",
      "0.09375\n",
      "start\n",
      "finish\n",
      "0.21875\n",
      "start\n",
      "finish\n",
      "0.09375\n",
      "start\n",
      "finish\n",
      "0.125\n",
      "start\n",
      "finish\n",
      "0.25\n",
      "start\n",
      "finish\n",
      "0.21875\n",
      "start\n",
      "finish\n",
      "0.25\n",
      "start\n",
      "finish\n",
      "0.0625\n",
      "start\n",
      "finish\n",
      "0.21875\n",
      "start\n",
      "finish\n",
      "0.15625\n",
      "start\n",
      "finish\n",
      "0.25\n",
      "start\n",
      "finish\n",
      "0.1875\n",
      "start\n",
      "finish\n",
      "0.125\n",
      "start\n",
      "finish\n",
      "0.34375\n",
      "start\n",
      "finish\n",
      "0.1875\n",
      "start\n",
      "finish\n",
      "0.4375\n",
      "start\n",
      "finish\n",
      "0.59375\n"
     ]
    }
   ],
   "source": [
    "if If_RL == 0:\n",
    "    model=load_Res()\n",
    "    R_L,RR_L=R_layers(model,x_dist,y_dist)\n",
    "    progress[\"RR_L\"].append(RR_L)\n",
    "    progress[\"RL_exist\"] = 1\n",
    "    save_progress(progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "31207614-db9b-46fb-abe8-c92b31043729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0, 0.0, -0.25, -0.125, 0.0625, -0.125, 0.0625, 0.0625, 0.1875, 0.0625, 0.03125, 0.09375, 0.0625, 0.03125, 0.125, 0.0625, 0.125, 0.0, -0.03125, 0.09375, 0.15625, 0.1875, 0.234375, 0.140625, 0.203125, 0.15625, 0.265625, 0.515625]]\n"
     ]
    }
   ],
   "source": [
    "print(progress[\"RR_L\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bfdd6ff4-f7a0-438d-9097-74e7d681a6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeats=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "171ef852-2bcc-41f1-949e-a1f32729fa65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for lam_idx in range(start_lr_idx, len(Lam)):\n",
    "    lam = Lam[lam_idx]\n",
    "    for rep in range(start_repeat, repeats):\n",
    "        print(f\"\\n lambda: Lam={lam}, Repeat={rep+1}/{repeats}\")\n",
    "        if progress[\"Cri_exist\"] == 0:\n",
    "            model=load_Res()\n",
    "            weight_list,channel_label=prune_model(model,G,P,x_dist,y_dist,lam)\n",
    "            model_p=model_pr(model,weight_list,channel_label)\n",
    "            flops_p,par_p=compute_flops_params(model_p)\n",
    "            P_=par_p/par\n",
    "            F=flops_p/flops\n",
    "            C_P=channel_G(model_p)\n",
    "            print(flops_p,flops)\n",
    "            progress[\"P_list\"].append(P_)\n",
    "            progress[\"F_list\"].append([flops_p,F])\n",
    "            progress[\"C_list\"].append([C_P])\n",
    "            progress[\"Cri_exist\"] = 1\n",
    "            save_progress(progress)\n",
    "            model_p.save(\"Res_56_pruned.h5\")\n",
    "        else:\n",
    "            model_p=model_p=tf.keras.models.load_model('Res_56_pruned.h5',custom_objects={\n",
    "                'CustomWeightDecaySGD': CustomWeightDecaySGD,\n",
    "                'WarmUpCosine': WarmUpCosine})\n",
    "            flops_p,par_p=compute_flops_params(model_p)\n",
    "            F=flops_p/flops\n",
    "            print(flops_p,flops)\n",
    "        retrain(model_p,x_train,y_train_onehot,x_test,y_test_onehot)\n",
    "        loss_p, acc_p = model_p.evaluate(x_test, y_test_onehot)\n",
    "        print(f\" Finished: Lam={lam}, Repeat={rep+1}, Acc={acc_p:.4f}\")\n",
    "        progress[\"results\"].append(acc_p)\n",
    "        progress[\"last_lam_idx\"] = lam_idx\n",
    "        progress[\"last_repeat\"] = rep+1\n",
    "        save_progress(progress)\n",
    "    progress[\"E_list\"].append(sum(progress[\"results\"])/(repeats*acc))\n",
    "    progress[\"results\"]=[]\n",
    "    progress[\"Cri_exist\"] = 0\n",
    "    progress[\"last_lam_idx\"] = lam_idx + 1\n",
    "    progress[\"last_repeat\"] = 0\n",
    "    start_repeat=0\n",
    "    save_progress(progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1fe64fec-8ff3-423b-a273-89fa264d08ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.938, 0.9367, 0.941]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0.9380,0.9367,0.9410]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "11f12346-a854-4f65-a48e-200b3446e6f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9483, 0.9467, 0.9507]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0.9483,0.9467,0.9507]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "778f80e9-4c93-4d2f-861a-10fe25996ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9437, 0.9487, 0.9453]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0.9437,0.9487,0.9453]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "867f63e7-6898-4d97-9120-d7dd24978602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9483, 0.9487, 0.95]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0.9483,0.9487,0.9500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b93ab70-2d82-4cc0-abcf-05adf61eb4c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d94ef6-8cfe-4146-b2a1-8935e38478c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc553ff9-b8cc-428e-9b09-6063038d77f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4d4e90d0-cc08-4df5-b26b-6c81aaacae39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9407, 0.9393, 0.9413]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0.9407,0.9393,0.9413]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fcc9b9b2-3e96-4a1e-ab1d-95d0d308d3fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9467, 0.9417, 0.9457]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0.9467,0.9417,0.9457]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0e180b-9a35-4019-ae36-06b39bce0b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bc6dcd-8433-4553-b8ce-6602fab7d4d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fa8a552b-eb4f-4a07-9430-922795f3b17e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9437, 0.9393, 0.9407]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0.9437,0.9393,0.9407]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "84fce09d-f7e0-4ab3-ae69-55101e722688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9487, 0.948, 0.9483]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0.9487,0.9480,0.9483]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "72f9ddc6-3271-427e-aac9-b2d45614057d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9463, 0.9447, 0.951]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0.9463,0.9447,0.9510]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e29153e4-ea5a-4eea-a6b1-11c139d38f5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9523, 0.9453, 0.95]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0.9523,0.9453,0.9500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81497fe6-8bb8-4bb0-b8ef-29a2ff3f7bb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b85d037-c68e-4948-8bdc-044274088782",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05cea08-167f-4079-973e-c2499f1e4adc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abab6d05-d731-40a3-966b-18fc8ab29075",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf44490-4833-4b01-a8fb-567c61a41fbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
